\chapter{Linear Representations of Groups}





\section{Group Actions}


\begin{notation}
  If $G$ is a group then we denote by $e \in G$ the neutral element, by $gh$ the composition of $g,h \in G$ and by $g^{-1}$ the inverse of $g \in G$.
\end{notation}


\begin{definition}
  Given a group $G$ and a set $X$, an \emph{action of $G$ on $X$} is a map
  \begin{gather*}
            \pi
    \colon  G \times X
    \to     X \,,
    \quad   (g,x)
    \to     g.x \,,
  \shortintertext{such that}
    e.x = x
    \quad\text{and}\quad
    (gh).x = g.(h.x)
  \end{gather*}
  for all $x \in X$, $g, h \in G$.
  A \emph{$G$-set} is a set $X$ together with an action of $G$ on $X$.
\end{definition}


\begin{example}
  Given a set $X$, the set
  \[
              S(X)
    \defined  \{
                f \colon X \to X
              \suchthat
                \text{$f$ is bijective}
              \}
  \]
  carries a group structure via $fg \defined f \circ g$ (composition of maps) for all $f, g \in S(X)$. The neutral element is given by the identity $\id_X$.
\end{example}


\begin{definition}
  This above group is called the \emph{symmetry group of $X$}.
\end{definition}


\begin{fluff}
  Given a group action $\pi \colon G \times X \to X$, any group element $g \in G$ induces a bijection $\pi_g \in S(X)$ which is given by
  \[
              \pi_g(x)
    \defined  g.x
  \]
  for all $x \in X$, $g \in G$.
  The resulting map $\pi \colon G \to S(X)$, $g \mapsto \pi_g$ is a group homomorphism because
  \[
      \pi_{gh}(x)
    = (gh).x
    = g.(h.x)
    = \pi_g( \pi_h(x) )
    = (\pi_g \pi_h)(x)
  \]
  for all $g,h \in G$, $x \in X$.

  If on the other hand $\varphi \colon G \to S(X)$ is any group homomorphism, then the map
  \[
            \mathring{\varphi}
    \colon  G \times X
    \to     X,
    \quad   (g,x)
    \mapsto \varphi(g)(x)
  \]
  is an action of $G$ on $X$ because
  \begin{gather*}
      e.x
    = \varphi(e)(x)
    = \id_X(x)
    = x
  \shortintertext{und}
      (gh).x
    = \varphi(gh)(x)
    = (\varphi(g) \varphi(h))(x)
    = \varphi(g)( \varphi(h)(x) )
    = g.(h.x)
  \end{gather*}
  for all $g,h \in G$, $x \in X$.

  Both of these constructions are inverse to each other.
  This leads to the following result:
\end{fluff}


\begin{lemma}
  \label{lemma: G-actions = group homos G -> S(X)}
  For any group $G$ and set $X$ there is a 1:1-correspondence
  \begin{align*}
      \left\{
        \text{$G$-actions on $X$}
      \right\}
    & \xleftrightarrow{1:1}
      \left\{
        \text{group homomorphisms $G \to S(X)$}
      \right\} \,,
    \\
      \pi
    & \longmapsto
      \hat{\pi} \,,
    \\
      \mathring{\varphi}
    & \longmapsfrom
      \varphi \,.
  \end{align*}
\end{lemma}


From this lemma we get the idea that group actions are ``the same'' as ``representing'' groups as permutation groups.


\begin{example}
  Let $G$ be a group.
  \begin{enumerate}
    \item
      The group $G$ acts on itself by left multiplication, i.e.\
      \[
                  g.x
        \defined  gx
      \]
      for all $g \in G$, $x \in G$.
      This is called the \emph{\textup(left\textup) regular action of $G$}.
    \item
      The group $G$ acts onto itself by right multiplication with the inverse, i.e\
      \[
                  g.x
        \defined  xg^{-1}
      \]
      for all $g \in G$, $x \in G$.
      This is called the \emph{right regular action of $G$}.
    \item
      The group $G$ acts onto itself by conjugation, i.e.\
      \[
                  g.x
        \defined  gxg^{-1}
      \]
      for all $g \in G$, $x \in G$.
    \item
      Let $X$ be a set.
      Then
      \[
                  g.x
        \defined  x
      \]
      for all $g \in G$, $x \in X$ defines an action of $G$ on $X$.
      This action is called the \emph{trivial action} on $X$, and $X$ is called a \emph{trivial $G$-set}.
      This action corresponds to the trivial group homomorphism $G \to S(X)$.
    \item
      If $X, Y$ are $G$-sets then $G$ acts on $\Maps(X,Y) = \{f \suchthat f \colon X \to Y\}$ via
      \[
                  (g.f)(x)
        \defined g.\left( f\left( g^{-1}.x \right) \right)
      \]
      for all $f \in \Maps(X,Y)$, $g \in G$, $x \in X$.
      In the special case that $Y$ is a trivial $G$-set we have that
      \[
          (g.f)(x)
        = f(g^{-1}.x)
      \]
      for all $f \in \Maps(X,Y)$, $g \in G$ and $x \in X$.
    \item
      If $X, Y$ are $G$-sets then $G$ acts on $X \times Y$ via
      \[
                  g.(x,y)
        \defined (g.x,g.y)
      \]
      for all $g \in G$, $(x,y) \in X \times Y$.
    \item
      If $X$ is a set then the symmetry group $G \defined S(X)$ acts on $X$ via
      \[
                  f.x
        \defined  f(x)
      \]
      for all $f \in G$, $x \in X$.
      Note that the group homomorphism $S(X) \to S(X)$ which corresponds to this action is just the identity $\id_{S(X)} \colon S(X) \to S(X)$.
  \end{enumerate}
\end{example}


\begin{definition}
  Let $G$ be a group, and let $X$, $Y$ be $G$-sets.
  A map $f \colon X \to Y$ is called \emph{$G$-equivariant} if
  \[
      f(g.x)
    = g.f(x)
  \]
  for all $g \in G$ and $x \in X$.
  Then set of $G$-equivariant maps $X \to Y$ is denoted by
  \[
              \Hom_G(X,Y)
    \defined  \{
                f \colon X \to Y
              \suchthat
                \text{$f$ is $G$-equivariant}
              \} \,.
  \]
\end{definition}


\begin{lemma}
  Let $G$ be a group.
  \begin{enumerate}
    \item
      If $X$ is a $G$-set, then $\id_X \colon X \to X$ is $G$-equivariant.
    \item
      If $X$, $Y$, $Z$ are $G$-sets and $f_1 \colon X \to Y$ and $f_2 \colon Y \to Z$ are $G$-equivariant, then their composition $f_2 \circ f_1 \colon X \to Z$ is also $G$-equivariant.
  \end{enumerate}
\end{lemma}


\begin{example}
  Let $G$ be a group.
  \begin{enumerate}
    \item
      Consider $G$ as the regular $G$-set.
      Then $f \colon G \to G$ is $G$-equivariant if and only if $f$ is given by right multiplication with some element $a \in G$ (i.e\ if $f(g) = ga$ for all $g \in G$).
      \begin{proof}
        Assume there exists $a \in G$ such that $f(g) = ga$ for every $g \in G$.
        Then
        \[
            f(g.x)
          = f(gx)
          = gxa
          = g.f(x)
        \]
        for all $g \in G$, $x \in G$, so that $f$ is $G$-equivariant.
        If on the other hand $f \colon G \to G$ is $G$-equivariant, then it follows for $a \defined f(e)$ that
        \[
            f(g)
          = f(g.e)
          = g.f(e)
          = g.a
          = ga
        \]
        for every $g \in G$, so that $G$ is given by right multiplication with $a$.
      \end{proof}
    \item
      If $X$, $Y$ are trivial $G$-sets then every map $X \to Y$ is $G$-equivariant, so that $\Hom_G(X,Y) = \Maps(X,Y)$.
    \item
      If $X$ is any $G$-set and $Y$ is a trivial $G$-set then $f \colon X \to Y$ is $G$-equivariant if and only if $f(g.x) = f(x)$ for all $g \in G$, $x \in X$, i.e.\ if and only if $f$ is constant on the $G$-orbits of $X$.
  \end{enumerate}
\end{example}


\begin{fluff}
  The previous lemma shows that for every group $G$, the class of $G$-sets together with the $G$-equivariant maps between them form a category, which we will refer to as $\cGsets{G}$.
  The objects of $\cGsets{G}$ are $G$-sets and the $\Hom$-setits of $\cGsets{G}$ are given by
  \[
              \Hom_{\cGsets{G}}(X,Y)
    \defined  \Hom_G(X,Y)
  \]
  for all $G$-sets $X$ and $Y$.
\end{fluff}


\begin{definition}
  For every $G$-set $X$ let $X/G$ be the \emph{set of $G$-orbits} in $X$.
\end{definition}


\begin{fluff}
  Note that the action of $G$ on $X$ induces an action of $G$ on $X/G$, which is trivial.
  The canonical map
  \[
            \can
    \colon  X
    \to     X/G \,,
    \quad   x
    \mapsto G.x
    =       \text{$G$-orbit of $x$}
  \]
  is $G$-equivariant because
  \[
      \can(g.x)
    = G.g.x
    = G.x
    = \can(x)
    = g.\can(x)
  \]
  for all $g \in G$, $x \in X$.
\end{fluff}


\begin{definition}
  Let $X$ be a $G$-set.
  An element $x \in G$ with $g.x = x$ is called \emph{$G$-invariant} or a \emph{$G$ fixed point}.
  The set of $G$-invariants is denoted by
  \[
              X^G
    \defined  \{
                x \in X
              \suchthat
                \text{$g.x = x$ for all $g \in G$}
              \} \,.
  \]
\end{definition}


\begin{lemma}
  Let $X$, $Y$ be $G$-sets and let $f \colon X \to Y$ be $G$-equivariant.
  Then
  \[
              f\left( X^G \right)
    \subseteq Y^G \,.
  \]
\end{lemma}


\begin{proof}
  For every $x \in X^G$ we have that
  \[
      g.f(x)
    = f(g.x)
    = f(x)
  \]
  for all $g \in G$ and thus $f(x) \in Y^G$.
\end{proof}


\begin{fluff}
  This lemma shows that every $G$-equivariant map $f \colon X \to Y$ between $G$-sets $X$ and $Y$ induces a map $f^G \colon X^G \to Y^G$ by restriction.
  For every $G$-set $X$ one has
  \[
      \id_X^G
    = \id_{X^G} \,,
  \]
  and for all $G$-sets $X$, $Y$, $Z$ and $G$-equivariant maps $f \colon X \to Y$, $g \colon Y \to Z$ one has
  \[
      (g \circ f)^G
    = g^G \circ f^G \,.
  \]
  This shows that $(-)^G \colon \cGsets{G} \to \cGsets{G}$ defines a functor.
  (That $f^G$ is $G$-equivariant follows from the actions of $G$ on $X^G$ and $Y^G$ being trivial.)
\end{fluff}


\begin{lemma}
  \label{lemma: equivariants are invariants}
  Let $X$, $Y$ be $G$-sets.
  Then $\Hom_G(X,Y) = \Maps(X,Y)^G$.
\end{lemma}
\begin{proof}
  For every map $f \colon X \to Y$ one has that
  \begin{align*}
          f \in \Hom_G(X,Y)
    &\iff \text{$f(g.x) = g.f(x)$ for all $g \in G$, $x \in X$} \\
    &\iff \text{$f\left( g^{-1}.x \right) = g^{-1}.f(x)$ for all $g \in G$, $x \in X $} \\
    &\iff \text{$g.f\left( g^{-1}.x \right) = f(x)$ for all $g \in G$, $x \in X$} \\
    &\iff \text{$g.f = f$ for all $g \in G$}  \\
    &\iff f \in \Maps(X,Y)^G \,.
    \qedhere
  \end{align*}
\end{proof}


\begin{definition}
  Let $X$ be a $G$-set and let $k$ be field (or a ring).
  A map $f \colon X \to k$ is called \emph{invariant} or \emph{$G$-invariant} if
  \[
      f(x)
    = f\left( g.x \right)
  \]
  for all $g \in G$, $x \in X$.
\end{definition}


\begin{fluff}
  If we consider $k$ as a trivial $G$-set then a map $f \colon X \to k$ is $G$-invariant if and only if $f \in \Hom_G(X,k) = \Hom(X,k)^G$.
  So both notions of $G$-invariance agree.
\end{fluff}


\begin{lemma}
  Let $X$ be a $G$-set and let $k$ be field (or a ring).
  Then a map $f \colon X \to k$ is invariant if and only if $f$ factors through the canonical projection $\can \colon X \to X/G$, i.e.\ if there exists a map $\bar{f} \colon X/G \to k$ which makes the following diagram commute:
  \[
    \begin{tikzcd}
        X
        \arrow{rr}{f}
        \arrow[swap]{rd}{\can}
      & {}
      & k
      \\
        {}
      & X/G
        \arrow[swap, dashed]{ru}{\bar{f}}
      & {}
    \end{tikzcd}
  \]
\end{lemma}
\begin{proof}
  Both conditions are equivalent to $f$ being constant on the $G$-orbits of $X$.
\end{proof}


\begin{example}
  Let $G = \{e,s\} \cong \Integer/2$ where $e$ is the neutral element and $s^2 = e$.
  Let $G$ act on $X = \Real$ by $e.\lambda = \lambda$ and $s.\lambda = -\lambda$ for all $\lambda \in \Real$.
  We want to know for which $n$ the map $p_n \colon \Real \to \Real$, $x \mapsto x^n$ is $G$-invariant.
  For this we need to check for which $n$ we have that
  \[
      p_n(\lambda)
    = p_n\left( s^{-1}.\lambda \right)
    = p_n(s.\lambda)
    = p_n(-\lambda)
    = (-1)^n p_n(\lambda)
  \]
  for all $\lambda \in \Real$.
  This holds if and only if $n$ is even.
\end{example}


\begin{lemma}\label{lemma: basis of Maps and Hom}
  Let $X$ be a finite $G$-set and let $k$ be a field (or a ring).
  \begin{enumerate}
    \item
      The set $\Maps(X,k)$ forms a $k$-vector space (resp.\ $k$-module) via pointwise addition and scalar multiplication.
    \item
      A $k$-basis of $\Maps(X,k)$ is given by the maps $\chi_x$, $x \in X$ with
      \[
          \chi_x(y)
        = \delta_{xy}
        = \begin{cases}
            1 & \text{if $x = y$} \,, \\
            0 & \text{otherwise}  \,,
          \end{cases}
      \]
      for all $y \in X$.
    \item
      The set of invariant maps $\Maps(X,k)^G = \Hom_G(X,k)$ is a $k$-linear subspace (resp.\ $k$-submodule) of $\Maps(X,k)$.
    \item
      A $k$-basis of $\Maps(X,k)^G$ is given by the maps $\chi_\mc{O}$, $\mc{O} \in X/G$ with
      \[
          \chi_\mc{O}(y)
        = \begin{cases}
            1 & \text{if $y \in \mc{O}$} \,,  \\
            0 & \text{otherwise} \,,
          \end{cases}
      \]
      for all $y \in X$.
  \end{enumerate}
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      This is clear.
    \item
      For $f \in \Maps(X,k)$ one has that $f = \sum_{x \in X} f(x) \chi_x$.
      (Note that this sum is finite, hence well defined.)
      This is true since for every $y \in X$ we have that
      \[
          \left( \sum_{x \in X} f(x)  \chi_x \right)(y)
        = \sum_{x \in X} f(x) \underbrace{\chi_x(y)}_{= \delta_{xy}}
        = f(y) \,.
      \]
      This shows that the maps $\chi_x$, $x \in X$ generate $\Maps(X,k)$.
      They are linear independent since for all coefficients $\alpha_x \in k$, $x \in X$ with $\sum_{x \in X} \alpha_x \chi_x = 0$ one has for every $y \in X$ that
      \[
          \alpha_y
        = \sum_{x \in X} \alpha_x \underbrace{ \chi_x(y) }_{= \delta_{xy}}
        = 0 \,.
      \]
    \item
      \label{enum: invariants form a submodule}
      We need to check that for all $f, f_1, f_2 \in \Maps(X,k)^G$ and $\lambda \in k$ we have that $f_1 + f_2 \in \Maps(X,k)^G$ and $\lambda f \in \Maps(X,k)^G$.
      This holds because
      \begin{align*}
            (g.(f_1+f_2))(x)
        &=  (f_1+f_2)\left(g^{-1}.x\right)
         = f_1\left(g^{-1}.x\right) + f_2\left(g^{-1}.x\right) \\
        &=  f_1(x) + f_2(x) = (f_1+f_2)(x)
      \shortintertext{and}
            (g.(\lambda f))(x)
        &=  (\lambda f)\left(g^{-1}.x\right)
         = \lambda f\left(g^{-1}.x\right)
         = \lambda f(x)
         = (\lambda f)(x)
      \end{align*}
      for all $x \in X$.
    \item
      \label{enum: basis of the submodule of invariants}
      The maps $\chi_{\mc{O}}$, $\mc{O} \in X/G$ are contained in $\Maps(X,k)^G$ since they are constant on the $G$-orbits of $X$.
      
      To see that they are a basis of $\Maps(X,k)^G$ let $\mc{O}_1, \dotsc, \mc{O}_n$ be the $G$-orbits in $X$, and for every $i = 1, \dotsc, n$ let $x_i$ be a representative of $\mc{O}_i$, i.e.\ let $x_i \in \mc{O}_i$.
      
      For every $f \in \Maps(X,k)^G$ one then has that $f = \sum_{i=1}^n f(x_i) \chi_{\mc{O}_i}$:
      For every $y \in X$ there exists a unique $j$ with $y \in \mc{O}_j$.
      Since the map $f$ and the maps $\chi_{\mc{O}_i}$ are constant on the $G$-orbits of $X$ it follows that
      \[
          \sum_{i=1}^n f(x_i) \chi_{\mc{O}_i}(y)
        = \sum_{i=1}^n f(x_i) \chi_{\mc{O}_i}(x_j)
        = f(x_j)
        = f(y) \,.
      \]
      This shows that the maps $\chi_{\mc{O}_i}$, $i = 1, \dotsc, n$ generate $\Maps(X,k)^G$.
      
      The linear independence follows in the same way as above:
      For all coefficients $\alpha_i \in k$, $i = 1, \dotsc, n$ with $\sum_{i=1}^n \alpha_i \chi_{\mc{O}_i}$ one has that
      \[
          0
        = \left( \sum_{i=1}^n \alpha_i \chi_{\mc{O}_i} \right)(x_j)
        = \sum_{i=1}^n \alpha_i \underbrace{ \chi_{\mc{O}_i}(x_j) }_{= \delta_{ij}}
        = \alpha_j
      \]
      for every $j = 1, \dotsc, n$.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{fluff}
  If $X$ is an infinite $G$-set then we can replace $\Maps(X,k)$ by
  \[
              kX
    \defined \{
                f \in \Maps(X,k)
              \suchthat
                \text{$\supp(f)$ is finite}
              \}
  \]
  where
  \[
      \supp(f)
    = \{
        x \in X
      \suchthat
        f(x) \neq 0
      \} \,,
  \]
  is the \emph{support of $f$}, i.e\
  \[
              kX
    = \{
        f \colon X \to k
      \suchthat
        \text{$f(x) \neq 0 $ for only finitely many $x \in X$}
      \} \,.
  \]
  Note that for all $f_1, f_2, f \in \Maps(X,k)$ and $\lambda \in k$ we have that
  \begin{gather*}
              \supp(f_1+f_2)
    \subseteq \supp(f_1) \cup \supp(f_2)
  \shortintertext{and}
              \supp(\lambda f)
    \subseteq \supp(f) \,.
  \end{gather*}
  Therefore $kX$ is a $k$-vector space (resp.\ $k$-module) via pointwise addition and scalar multiplication.

  Note that for every $x \in X$ we have that $\supp(\chi_x) = \{x\}$ and thus $\chi_x \in kX$.
  By using the same argumentation as above one finds that $\chi_x$, $x \in X$ is a $k$-basis of $kX$, i.e.\ that for every $f \in kX$ we have that $f = \sum_{x \in X} f(x) \chi_x$ (this sum is well-defined since only finitely many coefficients $f(x)$ are nonzero) and the maps $\chi_x$, $x \in X$ are linearly independent.

  The calculation from part~\ref{enum: invariants form a submodule} of the above proof shows that $kX^G \defined (kX)^G$ is a $k$-linear subspace (resp.\ $k$-submodule) of $kX$.
  We claim that the maps
  \[
    \chi_{\mc{O}}
    \quad\text{where}\quad
    \text{$\mc{O} \in X/G$ is finite}
  \]
  form a $k$-basis of $kX^G$.
  Let $\{\mc{O}_i \suchthat i \in I\}$ is the set of orbits with finitely many elements and $x_i \in \mc{O}_i$ is a representative.
  
  To see that the maps $\chi_{\mc{O}_i}$, $i \in I$ generate $kX^G$, let $f \in kX^G$.
  The map $f$ is constant on the $G$-orbits of $X$ because $f$ is $G$-invariant.
  Since $f$ has finite support it further follows that $f$ vanishes on all non-finite $G$-orbits.
  It therefore follows in the same way as in part~\ref{enum: basis of the submodule of invariants} of the above proof that $f = \sum_{i \in I} f(x_i) \chi_{\mc{O}_i}$.
  (This sum is finite because $f$ has finite support.) 
  It also follows as in part~\ref{enum: basis of the submodule of invariants} of the proof that the maps $\chi_{\mc{O}_i}$, $i \in I$ are linearly independent.
\end{fluff}


\begin{lemma}
  Let $X$ be a finite $G$-set.
  Suppose that $X = X_1 \dotcup X_2$ with $X_1, X_2 \neq \emptyset$ such that $g.x_1 \in X_1$ and $g.x_2 \in X_2$ for all $x_1 \in X_1$, $x_2 \in X_2$, $g \in G$.
  \begin{enumerate}
    \item
      $\Maps(X,k) \cong \Maps(X_1, k) \oplus \Maps(X_2, k)$ as $k$-vector spaces (resp.\ $k$-modules).
    \item
      $\Maps(X,k)^G \cong \Maps(X_1, k)^G \oplus \Maps(X_2, k)^G$ as $k$-vector spaces (resp.\ $k$-modules) where we have an induced action on both $\Maps(X_1, k)$ and $\Maps(X_2, k)$ from the $G$-action on $\Maps(X,k)$ via the isomorphism of the first part.
  \end{enumerate}
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      By Lemma~\ref{lemma: basis of Maps and Hom} the space $\Maps(X,k)$ has the basis $B \defined \{\chi_x \suchthat x \in X\}$.
      Similarly $\Maps(X_i, k)$ has the basis $B_i \defined \{\chi_x \suchthat x \in X_i\}$ for $i = 1, 2$.
      Since $X$ is the disjoint union of $X_1$ and $X_2$, it follows that there exists an isomorphism of $k$-vector spaces (resp.\ $k$-modules) $\Maps(X,k) \xrightarrow{\sim} \Maps(X_1, k) \oplus \Maps(X_2, k)$ given by
      \[
                \chi_x
        \mapsto \begin{cases}
                  (\chi_x,0) & \text{ if $x \in X_1$} \,,  \\
                  (0,\chi_x) & \text{ if $x \in X_2$} \,.
                \end{cases}
      \]
    \item
      The action of $G$ on $X$ restrict to actions of $G$ on both $X_1$ and $X_2$ since these are closed under the action of $G$.
      The group $G$ now acts on $\Maps(X, k)$ via $(g.f)(x) = f(g^{-1}.x)$ for all $g \in G$, $x \in X$, and simlilary on both $\Maps(X_1, k)$ and $\Maps(X_2, k)$.
      The above isomorphism $\Maps(X, k) \xrightarrow{\sim} \Maps(X_1, k) \oplus \Maps(X_2, k)$ is then $G$-equivariant.
      The invariants on the left side are $\Maps(X,k)^G$.
      The invariants on the right side are
      \[
          \left( \Maps(X_1, k) \oplus \Maps(X_2, k) \right)^G
        = \Maps(X_1, k)^G \oplus \Maps(X_2, k)^G,
      \]
      because $G$ acts componentwise on $\Maps(X_1, k) \oplus \Maps(X_2, k)$.
    \qedhere
  \end{enumerate}
\end{proof}


\begin{example}
  Let $X$ be a finite trivial $G$-set.
  It follows from the decomposition $X = \bigdotcup_{x \in X} \{x\}$ that
  \[
          \Maps(X,k)
    =     \gen{ \chi_x \suchthat x \in X }_k
    =     \bigoplus_{x \in X} k \chi_x
    \cong \bigoplus_{x \in X} \Maps(\{x\},k) \,.
  \]
  In this case we have $\Maps(X,k)^G = \Maps(X,k)$ because the $G$-action on $k$ is trivial.
\end{example}


\begin{warning}
  Given a $G$-set $X$ and a decomposition of $k$-vector spaces (resp.\ $k$-modules) $\Maps(X,k) = V \oplus W$ such that 
  \[
    g.v \in V
    \quad\text{and}\quad
    g.w \in W
  \]
  for all $v \in V$, $w \in W$, $g \in G$, then this decomposition is not necessarily arising from a decomposition $X = X_1 \dotcup X_2$ as above.
\end{warning}


\begin{example}
  Take for example the group $G = \{e,s\} \cong \Integer/2$ with $s^2 = e$ and let $G$ act on $X = G$ itself by left multiplication.
  Let $k$ be a field with $\kchar k \neq 2$.
  \begin{claim}
    There is no decomposition $X = X_1 \dotcup X_2$ as above.
  \end{claim}
  \begin{proof}
    If such a decomposition would exist then it would either be $X_1 = \{e\}$ and $X_2 = \{s\}$ or $X_1 = \{s\}$ and $X_2 = \{e\}$.
    But since $s.e = se = s$ and $s.s = ss = e$ we have in both cases that $s(X_1) \subseteq X_2$.
  \end{proof}
  
  The vector space $\Maps(X,k)$ has by Lemma~\ref{lemma: basis of Maps and Hom} a basis given by $\{\chi_e,\chi_s\}$ as a basis.
  Then $\{b_1, b_2\}$ with
  \[
              b_1
    \defined  \frac{\chi_e + \chi_s}{2}
    \quad\text{and}\quad
              b_2
    \defined  \frac{\chi_e - \chi_s}{2} \,.
  \]
  is also a basis of $\Maps(X,k)$.
  From $s.\chi_e = \chi_s$ and $s.\chi_s = \chi_e$ it follows that
  \[
      s.b_1
    = b_1
    \quad\text{and}\quad
      s.b_2
    = -b_2 \,.
  \]
  It follows for $V \defined \gen{b_1}_k$ and $W \defined \gen{b_2}_k$ that $\Maps(X, k) = V \oplus W$ with $g.v \in V$ and $g.w \in W$ for all $v \in V$, $w \in W$, $g \in G$.
\end{example}


\begin{lemma}
  \label{lemma: group action by ring automorphisms}
  Suppose the group $G$ acts on a ring $R$ by ring automorphisms (i.e.\ if $\pi \colon G \times R \to R$ is the action then $\pi_g \colon r \mapsto g.r$ is an ring automorphism of $R$ for every $g \in G$).
  Then $R^G$ is a subring of $R$, and therefore in a particular ring itself.
\end{lemma}


% \begin{remark}
%   Here rings don't necessarily have an 1-element.
% \end{remark}


\begin{proof}
  It holds for every $g \in G$ that $g.1 = \pi_g(1) = 1$, so that $1 \in R^G$.
  For all $r_1, r_2 \in R^G$, $g \in G$ it holds that
  \begin{gather*}
      g.(r_1 + r_2)
    = \pi_g(r_1 + r_2)
    = \pi_g(r_1) + \pi_g(r_2)
    = g.r_1 + g.r_2
    = r_1 + r_2
  \shortintertext{and}
      g.(r_1 r_2)
    = \pi_g(r_1 r_2)
    = \pi_g(r_1) \pi_g(r_2)
    = (g.r_1)(g.r_2)
    = r_1 r_2 \,,
  \end{gather*}
  so that $r_1 + r_2, r_1 r_2 \in R^G$.
\end{proof}


\begin{example}
  Let $X$ be a $G$-set and $k$ a field (or a ring).
  \begin{enumerate}
    \item
      The set $\Maps(X,k)$ carries the structure of a ring via pointwise addition and multiplication.
    \item
      The induced $G$-action on $\Maps(X,k)$ (i.e.\ $(g.f)(x) = f(g^{-1}.x)$ for all $g \in G$, $x \in X$) is an action by ring automorphisms:
      
      For all $g \in G$, $x \in X$ it holds that
      \[
          (g.1_{\Maps(X,k)})(x)
        = 1_{\Maps(X,k)}(g^{-1}.x)
        = 1
        = 1_{\Maps(X,k)}(x)
      \]
      and therefore $g.1_{\Maps(X,k)} = 1_{\Maps(X,k)}$.
      For all $f_1, f_2 \in \Maps(X,k)$, $g \in G$, $x \in X$ it holds that
      \begin{align*}
            (g.(f_1+f_2))(x)
        &=  (f_1+f_2)\left( g^{-1}.x \right)
          =  f_1\left( g^{-1}.x \right) + f_2\left( g^{-1}.x \right) \\
        &=  (g.f_1)(x) + (g.f_2)(x) = ((g.f_1)+(g.f_2))(x)
      \shortintertext{and}
            (g.(f_1 f_2))(x)
        &=  (f_1 f_2)\left( g^{-1}.x \right)
          =  f_1\left( g^{-1}.x \right) f_2\left( g^{-1}.x \right) \\
        &=  (g.f_1)(x) (g.f_2)(x) = ((g.f_1)(g.f_2))(x) \,.
      \end{align*}
      Alltogether this shows that $G$ acts by ring homomorphisms.
      Since $\pi_g$ has the inverse $\pi_{g^{-1}}$ these homomorphisms are automatically automorphisms.

     It follows from Lemma~\ref{lemma: group action by ring automorphisms} that $\Maps(X,k)^G$ is a subring of $\Maps(X,k)$.
    \item
      The symmetric group $S_n$ acts on the polynomial ring $k[X_1, \dotsc, X_n]$ via
      \[
          \sigma.p(X_1, \dotsc, X_n)
        = p(X_{\sigma(1)}, \dotsc, X_{\sigma(n)})
      \]
      for all $\sigma \in S_n$, $p(X_1, \dotsc, X_n) \in k[X_1, \dotsc, X_n]$.
      This is an action by ring automorphisms, so that $k[X_1, \dotsc, X_n]^{S_n}$ is a subring.
      This is the ring of \emph{symmetric polynomials}.
  \end{enumerate}
\end{example}


\begin{remark}
  Similar statements hold for $kX$ and $(kX)^G$ (with the same proofs).
\end{remark}


\begin{definition}
  Let $G$, $H$ be groups and let $X$ be both a $G$-set and $H$-set.
  Then the actions of $G$ and $H$ on $X$ \emph{commute} if
  \[
      h.(g.x)
    = g.(h.x)
  \]
  for all $g \in G$, $h \in H$, $x \in X$.
\end{definition}


\begin{remark}
  In this case we have that $\pi_g$ is an $H$-equivariant map for every $g \in G$ and that $\pi'_h$ is a $G$-equivariant map for every $h \in H$, because
  \[
      g.\pi_h(x)
    = \pi_g(h.x)
    = g.(h.x)
    = h.(g.x)
    = h.\pi_g(x)
    = \pi_h(g.x)
  \]
  for all $g \in G$, $h \in H$.
\end{remark}


\begin{example}
  \label{example: commuting actions}
  Let $G$ be a group.
  \begin{enumerate}
    \item
      Then the left regular action and the right regular action of $G$ on $G$ commute.
    \item
      The left regular action and conjugation action on $G$ commute if and only if $G$ is abelian:
      If $.$ denotes the left regular action and $*$ the conjugation then
      \begin{align*}
            g_1*(g_2.x)
        &=  g_1 (g_2 x) g_1^{-1}
         =  g_1 g_2 x g_1^{-1} \,,
        \tag{\ensuremath{\ast}}
        \\
            g_2.(g_1*x)
        &=  g_2 \left(g_1 x g_1^{-1}\right)
         =  g_2 g_1 x g_1^{-1}
        \tag{\ensuremath{\ast\ast}} \,,
      \end{align*}
      for all $g_1, g_2, x \in G$.
      Therefore
      \begin{align*}
            &\, \text{$(\ast) = (\ast\ast)$ for all $g_1, g_2, x \in G$}  \\
        \iff&\, \text{$g_1 g_2 = g_2 g_1$ for all $g_1, g_2 \in G$}       \\
        \iff&\, \text{$G$ is abelian} \,.
      \end{align*}
    \item
      Let $G \defined \GL(2,\Real)$.
      Then $G$ acts on $\Real^2$ in the natural way.
      Consider the subgroup
      \[
                  H
        \defined  \left\{
                    \begin{pmatrix}
                      \lambda & 0       \\
                      0       & \lambda
                    \end{pmatrix}
                  \suchthat*
                    \lambda \in \Real,
                    \lambda \neq 0
                  \right\}
        \subseteq \GL(2,\Real) \,.
      \]
      Then $H$ acts on $\Real^2$ by restriction of the $G$-action.
      The two actions commute since $gh = hg$ for all $g \in G$, $h \in H$.
      (Note that $H$ is the center of $G$.)
  \end{enumerate}
\end{example}


\begin{remark}
  Let $G, H$ be two groups and let $X$ be a set.
  %TODO: Commuting acting = Actions of GxH
\end{remark}





\section{Representations of Groups}


\begin{definition}
  Let $G$ be a group, $V$ a $k$-vector space and $\pi \colon G \times V \to V$ a group action.
  The action $\pi$ is \emph{\textup($k$-\textup)linear} if for every $g \in G$ the map $\pi_g \colon V \to V$, $v \mapsto g.v$ is ($k$-)linear.
  A \emph{$G$-space}, or \emph{representation of $G$} is a vector space $V$ together with a linear action of $G$ on $V$.
\end{definition}


\begin{example}
  The natural action of $\GL(2,\Real)$ on $\Real^2$ from Example~\ref{example: commuting actions} is $\Real$-linear.
\end{example}


\begin{notation}
  For any $k$-vector space $V$ we set
  \[
              \GL(V)
    \defined  \{
                f \colon V \to V
              \suchthat
                \text{$f$ is $k$-linear and invertible}
              \} \,.
  \]
\end{notation}


\begin{lemma}
  \label{lemma: linear G-actions = group homos G -> GL(V)}
  Let $G$ be a group and $V$ a $k$-vector space.
  Then the 1:1-correspondence
  \[
    \left\{
      \text{$G$-actions on $X$}
    \right\}
    \xlongleftrightarrow{1:1}
    \left\{
      \text{group homomorphisms $G \to S(V)$}
    \right\} \,.
  \]
  from Lemma~\ref{lemma: G-actions = group homos G -> S(X)} restrict to a 1:1-correspondence
  \[
    \left\{
      \text{linear $G$-actions on $X$}
    \right\}
    \xlongleftrightarrow{1:1}
    \left\{
      \text{group homomorphisms $G \to \GL(V)$}
    \right\} \,.
  \]
\end{lemma}


\begin{remark}
  By Lemma~\ref{lemma: linear G-actions = group homos G -> GL(V)}, a representation of $G$ can be equivalently characterized as a group homomorphism $\rho \colon G \to \GL(V)$ for a vector space $V$.
\end{remark}


\begin{example}
  Let $G$ be a group and $k$ a field.
  \begin{enumerate}
    \item
      Let $V$ be a $k$-vector space.
      Then $\GL(V)$ acts linearly on $V$ via
      \[
                  \varphi.v
        \defined  \varphi(v)
      \]
      for all $\varphi \in \GL(V)$, $v \in V$.
      Note that this action corresponds to the identity homomorphism $\id_{\GL(V)} \colon \GL(V) \to \GL(V)$.
    \item
      If $V$ is any $k$-vector space, then the trivial action of $G$ on $V$ is $k$-linear, and corresponds to the trivial group homomorphism $G \to \GL(V)$.
      This actions defined the \emph{trivial representation} of $G$ on $V$.
      For each fixed dimension there is (up to isomorphism) one trivial representation, which is the referred to as \emph{the} trivial representation (of dimension $\dim V$).
    \item
      The symmetric group $S_n$ acts linearly on $k^n$ such that
      \[
        \sigma.e_i = e_{\sigma(i)}
      \]
      for all $\sigma \in S_n$, $i = 1, \dotsc, n$, where $e_1, \dotsc, e_n$ denotes the standard basis of $k^n$.
      This action can also be written as
      \[
          \sigma.(a_1, \dotsc, a_n)
        = ( a_{\sigma^{-1}(1)}, \dotsc, a_{\sigma^{-1}(n)} )
      \]
      for all $\sigma \in S_n$, $(a_1, \dotsc, a_n) \in k^n$.
    \item
      For every $k$-vector space $V$ the symmetric group $S_n$ also acts linearly on $V^{\otimes n}$ via
      \[
          \sigma.(v_1 \otimes \dotsb \otimes v_n)
        = v_{\sigma^{-1}(1)} \otimes \dotsb \otimes v_{\sigma^{-1}(n)}
      \]
      for all $\sigma \in S_n$, $v_1, \dotsc, v_n \in V$.
    \item
      The group $S_n$ acts linearly on the polynomial ring $k[X_1, \dotsc, X_n]$ via
      \[
          \sigma.p(X_1, \dotsc, X_n)
        = p(X_{\sigma(1)}, \dotsc, X_{\sigma(n)}) \,.
      \]
      (Note that this is also an action by ring automorphisms, and therefore alltogether an action by $k$-algebra automorphisms.)
    \item
      The symmetric group $S_n$ acts linearly on $k$ such that $\sigma \in S_n$ acts by multiplication with $\sgn \sigma \in \{1, -1\}$.
      This defines the \emph{sign representation} of $S_n$.
      
      For $n \geq 2$ this is the only non-trivial one-dimensional representation of $S_n$:
      Note that every one-dimensional representation $V$ of $S_n$ corresponds to a group homomorphism $S_n \to \GL(V) \cong \GL_1(k)$, which is abelian.
      This homomorphism factors through the abelianization $S_n/[S_n, S_n] = S_n/A_n \cong \Integer/2$; it is therefore the trivial homomorphism or the sign homomorphism.
    \item
      If $X$ is a $G$-set then $G$ acts linearly on the vector space $kX$ via
      \[
          g.\left(\sum_{x \in X} a_x \chi_x\right)
        = \sum_{x \in X} a_x \chi_{g.x}
      \]
      where almost all $a_x$ are zero.
      This agrees with the previous action $*$ on $kX$, because
      \[
          (g * \chi_x)(y)
        = \chi_x(g^{-1}.y)
        = \delta_{x, g^{-1}.y}
        = \delta_{g.x, y}
        = \chi_{g.x}(y)
        = (g.\chi_x)(y)
      \]
      for all $g \in G$, $x, y \in X$.
    \item
      Let $V$ and $W$ be representations of $G$ over $k$.
      Then the induced $G$-action on $\Maps(V,W)$ induces a linear action of $G$ on $\Hom(V,W)$:
      
      For every $g \in G$ the maps $\pi_g \colon V \to V$, $v \mapsto g.v$ and $\tau_g \colon W \to W$, $w \mapsto g.w$ are linear because $G$ acts linearly on both $V$ and $W$.
      It follows for every $g \in G$ and $f \in \Hom(V,W)$ that
      \[
            g.f
        =   \tau_g \circ f \circ \pi_{g^{-1}}
        \in \Hom(V,W) \,.
      \]
      Hence $\Hom(V,W)$ is closed under the action of $G$ on $\Maps(V,W)$, so that $G$ acts on $\Hom(V,W)$ by restriction.
      The map $\tau_g \circ (-) \circ \pi_{g^{-1}} \colon \Hom(V,W) \to \Hom(V,W)$ is linear for every $g \in G$, so that this action is linear.
    \item
      The previous example has an important special case:
      Let $V$ be a representation of $G$ over $k$.
      By letting $G$ act trivially on $k$ it follows that $G$ acts linearly on $V^* = \Hom(V,k)$ in such a way that
      \[
          (g.\varphi)(v)
        = \varphi( g^{-1}.v )
      \]
      for all $\varphi \in V^*$, $v \in V$.
      Note that this is the unique $G$-action on $V^*$ such that
      \[
          (g.\varphi)(g.v)
        = \varphi(v)
      \]
      for all $g \in G$, $v \in V$, i.e.\ such the actions on $V^*$ and $V$ are compatible with the canonical bilinear form
      \[
                \bil{-}{-}
        \colon  V^* \times V
        \to     k \,,
        \quad   (\varphi, v)
        \mapsto \varphi(v) \,.
      \]
    \item
      If $V$ and $W$ be representations of $G$ over the same field, then $G$ acts linearly on $V \oplus W$ and $V \otimes W$ via
      \begin{align*}
                  g.(v,w)
        &\defined (g.v,g.w) \,,       \tag{1}
        \\
                  g.(v \otimes w)
        &\defined (g.v) \otimes (g.w) \tag{2}
      \end{align*}
      for all $v \in V$, $w \in W$, $g \in G$.
      If the linear actions of $G$ on $V, W$ are denoted by
      \[
        \pi \colon G \times V \to V
        \quad\text{and}\quad
        \tau \colon G \times W \to W \,,
      \]
      then the induced actions
      \begin{align*}
        \pi \oplus \tau  \colon G \times (V \oplus W)  &\to V \oplus W  \,,
        \\
        \pi \otimes \tau \colon G \times (V \otimes W) &\to V \otimes W
      \end{align*}
      are given by
      \[
          (\pi \oplus \tau)_g
        = \pi_g \oplus \tau_g
        \quad\text{and}\quad
          (\pi \otimes \tau)_g
        = \pi_g \otimes \tau_g
      \]
      for every $g \in G$.
%       
%       Note that if $\pi \colon G \times V \to V$ is the action on $V$ and $\pi' \colon G \times W \to W$ is the action on $W$, then the action
%       
%       Notice that the linear action on $V \otimes W$ is induces by the linear action on $V \times W$:
%        then the action $\tau \colon G \times (V \times W) \to V \times W$ defined by (1) is given by $\tau_g = \pi_g \times \pi'_g$ for all $g \in G$.
%       The action $\tau' \colon G \times (V \otimes W) \to V \otimes W$ defined by (2) is then given by $\tau_g = \pi_g \otimes \pi'_g$ for all $g \in G$.
%       So $\tau'$ it is the unique action which makes the following diagram commute for every $g \in G$:
%       \[
%         \begin{tikzcd}[column sep = large]
%             V \times W
%             \arrow{r}{\pi_g \times \pi'_g}
%             \arrow{d}
%           & V \times W
%             \arrow{d}
%           \\
%             V \otimes W
%             \arrow{r}{\pi_g \otimes \pi'_g}
%           & V \otimes W
%         \end{tikzcd}
%       \]
      If $v_1, \dotsc, v_n$ is a basis of $V$ with respect to which $\pi_g$ is given by a matrix $A$, and $w_1, \dotsc, w_m$ a basis of $W$ with respect to which $\tau_g$ is given by a matrix $B$, then $(\pi \oplus \tau)_g$ and $(\pi \otimes \tau)_g$ are therefore given by the matrices
      \[
        \begin{pmatrix}
          A & 0 \\
          0 & B
        \end{pmatrix}
        \quad\text{and}\quad
        \begin{pmatrix}
          a_{11} B & a_{12} B & \cdots & a_{1m} B \\
          a_{21} B & a_{22} B & \cdots & a_{2m} B \\
            \vdots  &  \vdots  & \ddots &  \vdots  \\
          a_{n1} B & a_{n2} B & \cdots & a_{nm} B
        \end{pmatrix}
      \]
      with respect to the basis $(v_1,0), \dotsc, (v_n,0), (0,w_1), \dotsc, (0,w_m)$ of $V \oplus W$ and the basis $v_1 \otimes w_1, v_1 \otimes w_2, \dotsc, v_n \otimes w_m$ of $V \otimes W$.
    \item
      Let $V$ be a representation of $G$ and $\pi \colon G \times V \to V$ the corresponding linear action.
      Then for every $d \geq 0$ the group $G$ acts linearly on the exterior power $\bigwedge^d V$ and symmetric power $S^d V$ via
      \begin{align*}
                  g.(v_1 \wedge \dotsb \wedge v_d)
        &\defined (g.v_1) \wedge \dotsb \wedge (g.v_d) \,,
        \\
                  g.(v_1 \dotsm v_d)
        &\defined (g.v_m) \dotsm (g.v_d) \,.
      \end{align*}
      for all $g \in G$, $v_1, \dotsc, v_d$.
      If the corresponding linear actions are denoted by
      \[
        \bigwedge^d \pi \colon G \times \bigwedge^d V \to \bigwedge^d V
        \quad\text{and}\quad
        S^d(\pi) \colon G \times S^d(V) \to S^d(V) \,,
      \]
      then
      \[
          \left( \bigwedge^d \pi \right)_g
        = \bigwedge \pi_g
        \quad\text{and}\quad
          S^d(\pi)_g
        = S^d(\pi_g)
      \]
      for every $g \in G$.
  \end{enumerate}
\end{example}


\begin{definition}
    Let $V$ be a representation of $G$.
    \begin{itemize}
      \item
        A \emph{subrepresentation} of $V$ is a vector subspace $U \subseteq V$ such that $g.u \in U$ for all $g \in G$, $u \in U$.
        A subrepresentation $U \subseteq V$ is \emph{proper} if $U \neq V$.
      \item
        The representation $V$ is \emph{indecomposable} if it it nonzero and canâ€™t be written as $V = U_1 \oplus U_2$ where $U_1, U_2$ are proper subrepresentations of $V$.
      \item
        The representation $V$ is \emph{irreducible} or \emph{simple} if it is nonzero has no nontrivial proper subrepresentation, i.e.\ no subrepresentation $U \subseteq V$ with $0 \subsetneq U \subsetneq V$.
    \end{itemize}
\end{definition}


\begin{example}
  Let $G$ be a group and $k$ a field.
  \begin{enumerate}
    \item
      Let $V$ be a vector space and let $G$ act trivially on $V$.
      Then every linear subspace $U \subseteq V$ is a subrepresentation.
      The representation $V$ is indecomposable if and only if it is one-dimensional.
      It is also irreducible if and only if it is one-dimensional.
    \item
      Let $V$ be a representation of $G$.
      If $(U_i)_{i \in I}$ is any familiy of subrepresentations, then both $\sum_{i \in I} U_i$ and $\bigcap_{i \in I} U_i$ are again subrepresentations of $V$.
    \item
      Every finite dimensional representation can be written as a direct sum of indecomposable subrepresentations.
    \item
      Let $V$ be a representation of $G$ over $k$.
      For every subset $E \subseteq V$ there exists a smallest subrepresentation of $V$ containing $E$.
      This subrepresentation $\gen{E}_G \subseteq V$ can be described in the following equivalent ways:
      \begin{enumerate}
        \item
          One has that $E \subseteq \gen{E}_G$, and for every subrepresentation $U \subseteq V$ with $E \subseteq U$ one has that $\gen{E}_G \subseteq U$.
        \item
          The subrepresentation $\gen{E}_G$ is given by
          \[
              \gen{E}_G
            = \bigcap_{\substack{\text{subrep.\ $U \subseteq V$} \\ E \subseteq U}} U \,.
          \]
        \item
          The subrepresentation $\gen{E}_G$ is given by
          \[
              \gen{E}_G
            = \left\{
                \sum_{i=1}^n \lambda_i g_i.e_i
              \suchthat*
                n \geq 0,
                \lambda_i \in k,
                g_i \in G,
                e_i \in E
              \right\}
            = \gen{g.e \suchthat g \in G, e \in E}_k \,.
          \]
      \end{enumerate}
    \item
      A non-zero representation $V$ of $G$ is irreducible if and only if every non-zero $v \in V$ generates the representation $V$:
      
      Suppose that $V$ is irreducible and let $v \in V$ be non-zero.
      Then $\gen{v}_G$ is a non-zero subrepresentation of $V$, so that $\gen{v}_G = V$ by irreducibility.
      
      Suppose that $V$ is reducible.
      Then there exists an non-zero, proper subrepresentation $0 \subsetneq U \subsetneq V$.
      Then there exists some non-zero $v \in U$, for which it follows that $\gen{v} \subseteq U \subsetneq V$, so that $v$ does not generate $V$.
    \item
      The group $G \defined \Integer/n$, $n \geq 1$ acts on the plane $V \defined \Real^2$ by rotation, i.e.
      \[
                  \overline{n}.\vect{x \\ y}
        \defined  \begin{pmatrix*}[r]
                    \cos(2\pi/n)  & -\sin(2\pi/n) \\
                    \sin(2\pi/n)  &  \cos(2\pi/n)
                  \end{pmatrix*}
                  \vect{x \\ y}.
      \]
      Then $V$ is irreducible if and only if $n \geq 3$:
      
      For $n = 1$ the action is trivial, but $V$ is two-dimensional, and therefore reducible.
      For $n = 2$ every element $g \in G$ acts by multiplication with a scalar, so that every one-dimensional subspace is a non-zero proper subrepresentation.
      
      If $n \geq 3$ then for every non-zero vector $v \in V$ the two vectors $v, \overline{1}.v$ are linearly independent.
      Thus $V$ is spanned by $\{v, \overline{1}.v\}$ as a $\Real$-vector space and therefore also as a representation.
      This shows that every non-zero $v \in V$ generates the representation $V$, so that $V$ is irreducible.
    \item
      Let the symmetric group $S_n$ act linearly on the polynomial ring $k[X_1, \dotsc, X_n]$ via
      \[
          \sigma.p(X_1, \dotsc, X_n)
        = p(X_{\sigma(1)}, \dotsc, X_{\sigma(n)})
      \]
      for all $\sigma \in S_n$, $p(X_1, \dotsc, X_n) \in k[X_1, \dotsc, X_n]$.
      For every degree $d \geq 0$ let $k[X_1, \dotsc, X_n]_d$ denote the $k$-linear span of all monomials $X_1^{d_1} \dotsm X_n^{d_n}$ of degree $d_1 + \dotsb + d_n = d$.
      Then $k[X_1, \dotsc, X_n]_d$ is a subrepresentation of $k[X_1, \dotsc, X_n]$ because the action of $S_n$ on the monomials preserves the degree.
      This gives a decomposition $k[X_1, \dotsc, X_n] = \bigoplus_{d \geq 0} k[X_1, \dotsc, X_n]_d$ into finite-dimensional subrepresentations.
  \end{enumerate}
\end{example}


\begin{fluff}
  Every irreducible representation is also indecomposable, but as the following example shows, the converse is not true:
\end{fluff}

\begin{example}
  \label{example: upper triangular action on C2}
  Let
  \[
              G
    \coloneqq \left\{
                \begin{pmatrix}
                  a & b \\
                  0 & c
                \end{pmatrix}
              \,\middle|\,
                a, b, c \in \Complex
                \text{ and }
                a, c \neq 0
              \right\} .
  \]
  be the group of upper, triangular, complex $(2 \times 2)$-matrices.
  The group $G$ acts on the vector space $V \coloneqq \Complex^2$ in the natural way, i.e.\ via left multiplication.
  
  The representation $V$ is not irreducible because $U \coloneqq \vspan(e_1)$ is a subrepresentation.
  \begin{claim}
    The subrepresentation $U \subseteq V$ is the unique $1$-dimensional subrepresentation.
  \end{claim}
  From this claim it follows that there exists no proper subrepresentations $U_1, U_2$ of $V$ with $V = U_1 \oplus U_2$, so that $V$ is indecomposable.
  \begin{proof}[Proof of the claim]
    Let $W$ be any one-dimensional subrepresentation of $V$.
    Then
    \[
        W
      = \vspan\left\{
                \vect{\alpha \\ \beta}
              \right\}
      \quad
      \text{for some $0 \neq  \vect{\alpha \\ \beta} \in   \Complex^2$} \,.
    \]
    Because $W$ is a subrepresentation of $V$ it follows that
    \[
          \begin{pmatrix}
            1 & 1 \\
            0 & 1
          \end{pmatrix}
          \vect{\alpha \\ \beta}
      =   \vect{\alpha + \beta \\ \beta}
      \in W \,.
    \]
    and therefore that
    \[
      \vect{\beta \\ 0} \in W \,.
    \]
    If $\beta \neq 0$ then it follows that
    \[
      \vect{1 \\ 0} \in W \,,
    \]
    and if $\beta = 0$ then the same follows from $\alpha \neq 0$.
    Because $W$ is one-dimensional it follows that
    \[
        W
      = \vspan \left\{ \vect{1 \\ 0} \right\}
      = U \,.
    \]
    This proves the claim.
  \end{proof}
\end{example}


\begin{warning}
  Example~\ref{example: upper triangular action on C2} also show that subrepresentations do not necessarily have direct complements which are again subrepresentations.
\end{warning}


\begin{lemma}\label{lemma: direct sum and invariants commute}
  Let $G$ be a group.
  \begin{enumerate}
    \item
      Given a representation $V$ of $G$, the subset $V^G \subseteq V$ is a subrepresentation of $V$.
    \item
      For every collection $V_i$, $i \in I$ of representations of $G$ one has that
      \[
          \left(
            \bigoplus_{i \in I} V_i
          \right)^G
        = \bigoplus_{i \in I} V_i^G \,.
      \]
  \end{enumerate}
\end{lemma}
\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      Since $G$ acts trivially on $V^G$ it sufficies to check that $V^G$ is a vector subspace of $V$.
      This holds because $\pi_g \colon V \to V$, $v \mapsto g.v$ is linear for every $g \in G$ and
      \[
          V^G
        = \bigcap_{g \in G} \ker(\pi_g - \id_V) \,.
      \]
    \item
      Let $v \in \bigoplus_{i \in I} V_i$.
      Then $v = (v_i)_{i \in I}$ with $v_i = 0$ for all but finitely many $i \in I$.
      For every $g \in G$ one has that
      \[
          g.v
        = g.(v_i)_{i \in I}
        = (g.v_i)_{i \in I}
      \]
      and therefore
      \begin{align*}
              v \in \left( \bigoplus_{i \in I} V_i \right)^G
        &\iff \text{$g.v = v$ for every $g \in G$}  \\
        &\iff \text{$(g.v_i)_{i \in I} = (v_i)_{i \in I}$ for every $g \in G$} \\
        &\iff \text{$g.v_i = v_i$ for all $g \in G$, $i \in I$} \\
        &\iff \text{$v_i \in V_i^G$ for every $i \in I$}
         \iff v \in \bigoplus_{i \in I} V_i^G \,.
      \end{align*}
      This shows the claimed equality.
  \qedhere
  \end{enumerate}
\end{proof}





\section{Group Algebras}


\begin{definition}
  Let $k$ be a field (or a ring) and $G$ a group.
  Then the \emph{group algebra of $G$ over $k$} is the $k$-algebra given by the $k$-vector space
  \[
              k[G]
    \defined  \{
                f \colon G \to k
              \suchthat
                \text{$f(g) \neq 0$ for only finitely many $g \in G$}
              \}
  \]
  with pointwise addition and scalar multiplication, and multiplication given by convolution, i.e.\
  \begin{equation}
  \label{equation: multiplication by convolution}
      (f_1 \cdot f_2)(x)
    = \sum_{y \in G} f_1(y) f_2\left( y^{-1}x \right)
  \end{equation}
  for all $f_1, f_2 \in k[G]$, $x \in G$.
  The unit of the group algebra is given by the function $\chi_e$.
\end{definition}


\begin{fluff}
  To make it easier to work with the group algebra $k[G]$ we provide another way to think about it:

  Every function $f \in k[G]$ can be written as a linear combination $f = \sum_{g \in G} a_g \chi_g$ with $a_g \in k$ for every $g \in G$ (namely $a_g = f(g)$), where almost all of the coefficients $a_g$ are zero.
  Because the functions $\chi_g$, $g \in G$ form a basis of $k[G]$, the linear combination $\sum_{g \in G} a_g \chi_g$ can be identified with the formular linear combination $\sum_{g \in G} a_g g$.
  Note that $g \in G$ is then identified with $\chi_g \in k[G]$, so that $G$ becomes a $k$-basis of $k[G]$.
  
  The addition and scalar multiplication of $k[G]$ are then given by
  \begin{gather*}
        \left( \sum_{g \in G} a_g g \right)
      + \left( \sum_{g \in G} b_g g \right)
    = \sum_{g \in G} (a_g + b_g) g \,,
    \qquad
      \lambda \left( \sum_{g \in G} a_g g \right)
    = \sum_{g \in G} (\lambda a_g) g
  \end{gather*}
  for every $\lambda \in k$, and the multiplication of $k[G]$ is then given by
  \begin{equation}
  \label{equation: multiplication by bilinearity}
            \left( \sum_{g \in G} a_g g \right)
      \cdot \left( \sum_{g \in G} b_g g \right)
    = \sum_{g, g' \in G} a_g b_{g'} (g g') \,.
  \end{equation}
  To see that \eqref{equation: multiplication by bilinearity} defines the same multiplication as \eqref{equation: multiplication by convolution} note that
  \[
      \left( \chi_{g_1} \cdot \chi_{g_2} \right)(h)
    = \sum_{g \in G} \chi_{g_1}(g) \chi_{g_2}\left( g^{-1} h \right)
    = \chi_{g_2}\left( g_1^{-1}h \right)
    = \delta_{g_2, g_1^{-1} h}
    = \delta_{g_1 g_2, h}
    = \chi_{g_1 g_2}(h) \,,
  \]
  for every $h \in G$, so that
  \[
    \chi_{g_1} \cdot \chi_{g_2} = \chi_{g_1 g_2}
  \]
  for all $g_1, g_2 \in G$.
  This shows that the multiplications \eqref{equation: multiplication by convolution} and \eqref{equation: multiplication by bilinearity} agree on the $k$-basis $(\chi_g)_{g \in G}$, resp.\ $(g)_{g \in G}$ of $k[G]$, and thus on the whole of $k[G]$ by the $k$-bilinearity of both \eqref{equation: multiplication by convolution} and \eqref{equation: multiplication by bilinearity}.

  Alltogether this shows that we can think of the group algebra $k[G]$ as a linearization of the group $G$:
  The group $G$ is a $k$-basis of $k[G]$, the multiplication of $k[G]$ is the (unique) $k$-bilinear extension of the multiplication of $G$, and $e = 1_{k[G]}$ for the neutral element $e \in G$.
  Note also that $k[G]$ is commutative if and only if $G$ is abelian.
\end{fluff}


\begin{fluff}
  \label{fluff: correspondence between representations and module structures}
  If $V$ is a representation of a group $G$ over a field $k$, then the corresponding group homomorphismus $\rho \colon G \to \GL(V)$ can be regarded as a map $G \to \End(V)$, which then extends (uniquely) to a $k$-linear map
  \[
            R
    \colon  k[G]
    \to     \End(V) \,,
    \quad   \sum_{g \in G} a_g g
    \mapsto \sum_{g \in G} a_g \rho(g) \,.
  \]
  The $k$-linear map $R$ is multiplicative on the basis $G \subseteq k[G]$ because $\restrict{R}{G} = \rho$, and is therefore a homomorphisms of $k$-algebras.
  This homomorphisms corresponds to a $k[G]$-module structure on $V$ given by
  \[
              x \cdot v
    \defined  R(x)(v)
    =         R\left( \sum_{g \in G} a_g g \right)(v)
    =         \sum_{g \in G} a_g \rho(g)(v)
    =         \sum_{g \in G} a_g (g.v)
  \]
  for all $x = \sum_{g \in G} a_g g \in k[G]$, $v \in V$.
  
  If on the other hand $V$ is a $k[G]$-module, then the corresponding homomorphism of $k$-algebras
  \[
            T
    \colon  k[G]
    \to     \End(V),
    \quad   a
    \mapsto (v \mapsto a \cdot v)
  \]
  maps every group element $g \in G$ to linear map $T(g) \colon V \to V$ in a multiplicative way.
  Note that the linear map $T(g)$ is necessarily bijective because
  \[
      T(g) T(g^{-1})
    = T(g g^{-1})
    = T(e)
    = T(1_{K[G]})
    = \id_V \,.
  \]
  Hence $T$ restrict to a group homomorphism $\tau \defined \restrict{T}{G} \colon G \to \GL(V)$, which makes $V$ into a representation of $G$ given via
  \[
              g.v
    \defined  \tau(g)(v)
    =         T(g)(v)
    =         g \cdot v
  \]
  for all $g \in G$, $v \in V$.
  
  The above constructions are inverse to each other, and thus lead to the following result:
\end{fluff}


\begin{corollary}
  \label{corollary: correspondence between representations and module structures}
  Let $G$ be a group and $V$ a $k$-vector space.
  Then there exists a 1:1-correspondence
  \[
  \begin{matrix}
      \{ \text{$k$-linear $G$-actions on $V$} \}
    & \xleftrightarrow{1:1}
    & \{ \text{$k[G]$-module structures on $V$} \} \,, \\
      \pi
    & \longmapsto
    & P
    \end{matrix}
  \]
  where for every linear action $\pi \colon G \times V \to V$, $(g,v) \mapsto g.v$ the corresponding $k[G]$-module structure is given by
  \[
            P
    \colon  k[G] \times V
    \to     V \,,
    \quad   \left( \sum_{g \in G} a_g g, v \right)
    \mapsto \sum_{g \in G} a_g (g.v) \,.
  \]
\end{corollary}


\begin{remark}
  Note that the group algebra $k[G]$ is a module over itself via left multiplication.
  This $k[G]$-module structure corresponds to the linear action of $G$ on $k[G]$ via left multiplication on the basis vectors $h \in G$, i.e.
  \[
      g.\left( \sum_{h \in G} a_h h \right)
    = \sum_{h \in G} a_h (gh)
  \]
  for all $g \in G$, $\sum_{h \in G} a_h h \in k[G]$.
  This is the \emph{\textup(left\textup) regular representation} of $G$.
\end{remark}


\begin{remark}
  \label{remark: monoid algebra}
  Given any ring $R$ and monoid $M$ the \emph{monoid algebra} $R[M]$ is given by the set of all formal linear combination $\sum_{x \in M} r_x x$ (where $r_x = 0$ for all but finitely many $x \in M$) together with the addition
  \[
      \left( \sum_{x \in M} r_x x \right)
    + \left( \sum_{x \in M} s_x x \right)
    = \sum_{x \in M} (r_x + s_x) x \,,
  \]
  the scalar multiplication
  \[
      r \cdot \left( \sum_{x \in M} r_x x \right)
    = \sum_{x \in M} (r r_x) x \,,
  \]
  and the multiplication
  \[
          \left( \sum_{x \in M} r_x x \right)
    \cdot \left( \sum_{x \in M} s_x x \right)
    = \sum_{x, y \in M} (r_x s_y) (xy) \,.
  \]
  Then $R$ can be regarded as a subring of $R[M]$ via the inclusion
  \[
                    R
    \hookrightarrow R[M],
    \quad           r
    \mapsto         r 1_{R[M]} \,,
  \]
  and $M$ can be regarded as an $R$-basis of $R[M]$.
  The monoid algebra $R[M]$ has the following universal property:
  
  Let $S$ be any ring.
  Then every ring homomorphism $\Phi \colon R[M] \to S$ restrict to a ring homomorphism $\varphi \colon R \to S$ and to a monoid homomorphism $\psi \colon M \to (S, \cdot)$, while every pair $(\varphi', \psi')$ consisting of a ring homomorphism $\varphi' \colon R \to S$ and monoid homomorphism $\psi' \colon M \to (S, \cdot)$ extend to a ring homomorphism $\Phi' \colon R[M] \to S$.
  These constructions are inverse to each other and thus lead to a 1:1-correspondence
  \begin{align*}
                         &\,  \{ \text{ring homomorphism $\Phi \colon R[M] \to S$} \} \\
    \xleftrightarrow{1:1}&\,  \left\{
                                (\varphi, \psi)
                              \suchthat*
                                \begin{tabular}{c}
                                  ring homomorphisms $\varphi \colon R \to S$, \\
                                  monoid homomorphisms $\psi \colon M \to (S, \cdot)$
                                \end{tabular}
                              \right\} \,,
  \end{align*}
  given by the restriction(s) $\Phi \mapsto (\restrict{\Phi}{R}, \restrict{\Phi}{M})$.
  (The necessary calculations are the same as in \ref{fluff: correspondence between representations and module structures}.)
  
  If $M = G$ is a group then we retrieve the previous definition of the group algebra $R[G]$.
  Then the image of every monoid homomorphism $G \to (S,\cdot)$ is already contained in the unit group $S^\times$, and the universal property above becomes a 1:1-correspondence
  \begin{align*}
                         &\,  \{ \text{ring homomorphism $\Phi \colon R[G] \to S$} \} \\
    \xleftrightarrow{1:1}&\,  \left\{
                                (\varphi, \psi)
                              \suchthat*
                                \begin{tabular}{c}
                                  ring homomorphisms $\varphi \colon R \to S$, \\
                                  group homomorphisms $\psi \colon M \to S^\times$
                                \end{tabular}
                              \right\} \,.
  \end{align*}
  
  One can then retrieve Corollary~\ref{corollary: correspondence between representations and module structures} from the universal property of the group algebra:
  Suppose that $R = k$ is a field, $M = G$ is a group, $V$ is a $k$-vector space and $S = \End(V)$.
  Then by letting $\varphi \colon k \to \End(V)$ be the canonical inclusion $\lambda \mapsto \lambda \cdot 1_V$, we get a 1:1-correspondence
  \begin{align*}
                         &\,  \{ \text{$k$-algebra homomorphims $R \colon k[G] \to \End(V)$} \} \\
    \xleftrightarrow{1:1}&\,  \{ \text{group homomorphisms $\rho \colon G \to \End(V)^\times = \GL(V)$} \} \,,
  \end{align*}
  which is given by restriction $R \mapsto \restrict{R}{G}$.
\end{remark}


\begin{remark}
  Let $k$ be a commutative ring and let $\cAlg{k}$ be the category of $k$-algebras.
  Let $\cMon$ be the category of monoids.
  
  There exists a forgetful functor $U \colon \cAlg{k} \to \cMon$ which assigns to each $k$-algebra $S$ its underlying multiplicative monoid $U(S) = (S, \cdot)$, and which regards every $k$-algebra homomorphism $f \colon S \to T$ as a monoid homomorphism (i.e.\ multipicative map) $f \colon (S, \cdot) \to (T, \cdot)$.
  
  Note that every homomorphism of monoids $f \colon M \to N$ induces a homomorphism of $k$-algebras
  \[
            f_*
    \colon  k[M]
    \to     k[N] \,,
    \quad   \sum_{x \in M} a_x x
    \mapsto \sum_{x \in M} a_x f(x) \,,
  \]
  in such a way that $(\id_M)_* = \id_{k[M]}$ and $(g \circ f)_* = g_* \circ f_*$.
  The monoid algebra over $k$ can therefore be regarded as a functor $k[-] \colon \cMon \to \cAlg{k}$.
  
  The universal property of the monoid algebra then states that the functor $k[-]$ is left-adjoint to the forgetful functor $U$.
  This also holds true if $k$ is replaced by an arbitrary (not necessarily commutative) ring $R$, if one does not require $R$-algebras to be central.
\end{remark}





\section{Morphism of Representations \& Schurâ€™s Lemma}


\begin{definition}
Let $G$ be a group, $k$ a field and let $V$, $W$ be representations of $G$.
\begin{itemize}
  \item
    A map $f \colon V \to W$ is called a \emph{morphism of representations of $G$} or \emph{morphism of $G$-spaces} if it is both $k$-linear and $G$-equivariant.
    The space of morphisms of representations $V \to W$ is denoted by
    \[
                \Hom_G(V,W)
      \defined  \{
                  f \colon V \to W
                \suchthat
                  f \text{ is a morphism of representations}
                \} \,.
    \]
  \item
    An \emph{isomorphism of representations} is an morphism of representations which is also invertible, i.e.\ bijective.
  \item
    Two representations $V$ and $W$ are \emph{isomorphic}, denoted by $V \cong W$, if there exists an isomorphism of representations between $V$ and $W$.
\end{itemize}

\end{definition}


\begin{remark}
  If $f \colon V \to W$ is an isomorphism of representations, then its inverse $f^{-1}$ is again a morphism of representations:
  It is know from linear algebra that $f^{-1}$ is again linear.
  It is $G$-equivariant, because
  \[
      f^{-1}( g.v )
    = f^{-1}\left( g.f\left( f^{-1}( v ) \right) \right)
    = f^{-1}\left( f\left( g . f^{-1}( v ) \right) \right)
    = g.f^{-1}(v)
  \]
  for all $g \in G$, $v \in V$.
\end{remark}


\begin{example}
  Let $G$ be a group and $k$ a field.
  \begin{enumerate}
    \item
      If $V_1$, $V_2$, $W$ are representations of $G$, then the linear isomorphism
      \[
                \alpha
        \colon  (V_1 \oplus V_2) \otimes W
        \to     V_1 \times W \oplus V_2 \otimes W \,,
        \quad   (v_1, v_2) \otimes w
        \mapsto (v_1 \otimes w, v_2 \otimes w)
      \]
      is an isomorphism of representations because
      \begin{align*}
            \alpha( g . ((v_1,v_2) \otimes w) )
        &=  \alpha( (g.(v_1, v_2)) \otimes (g.w) )
         =  \alpha( (g.v_1, g.v_2) \otimes (g.w) )
        \\
        &=  ( (g.v_1) \otimes (g.w) , (g.v_2) \otimes (g.w) )
         =  ( g.(v_1 \otimes w), g.(v_2 \otimes w) )
        \\
        &=  g.(v_1 \otimes w, v_2 \otimes w)
         =  g.\alpha((v_1, v_2) \otimes w) \,.
      \end{align*}
    \item
      If $V$, $W$ are finite-dimensional representations of $G$, then the linear isomorphism
      \[
                \beta
        \colon  V^* \otimes W
        \to     \Hom(V,W) \,,
        \quad   \varphi \otimes w
        \mapsto (v \mapsto \varphi(v) w)
      \]
      is an isomorphism of representations because
      \begin{align*}
            \beta( g.(\varphi \otimes w) )(v)
        &=  \beta( (g.\varphi) \otimes (g.w) )(v)
         =  (g.\varphi)(v) (g.w)
         =  \varphi(g^{-1}.v) \cdot (g.w)
        \\
        &=  g.\left( \varphi(g^{-1}.v) w \right)
         =  g.\left( \beta(\varphi \otimes w)(g^{-1}.v) \right)
         =  (g.\beta(\varphi \otimes w))(v) \,,
      \end{align*}
      where we used for the fourth equality that $g \in G$ acts linearly on $W$.
    \item
      If $V$ is a representation of $G$ over $k$, then the evaluation homomorphism
      \[
                \alpha
        \colon  V^* \otimes V
        \to     k \,,
        \quad   \varphi \times v
        \mapsto \varphi(v)
      \]
      is a morphism of representations when we regard $k$ as the trivial representation.
      This holds because
      \begin{align*}
            \alpha(g.(\varphi \otimes v))
        &=  \alpha((g.\varphi) \otimes (g.v))
         =  (g.\varphi)(g.v)
        \\
        &=  \varphi(g^{-1}.g.v)
         =  \varphi(v)
         =  g.\varphi(v)
         =  g.\alpha(\varphi \otimes v) \,.
      \end{align*}
      Note that the linear action of $G$ on $V$ is defined precisely so that $\alpha$ is a morphism of representations.
    \item
      Let $V$ be a representation of $G$ over $k$ and regard $k$ as the trivial representation.
      Then for every $v \in V$ the homomorphism
      \[
                k
        \to     V \,,
        \quad   \lambda
        \mapsto \lambda v
      \]
      is a morphism of representations if and only if $g.(\lambda v) = \lambda v$ for every $\lambda \in K$, i.e.\ if and only if $v$ is $G$-invariant (as can be seen by considering $\lambda = 1$).
      Thus we have an isomorphism of vector spaces (which is also an isomorphism of trivial representations)
      \[
                \Hom_G(k,V)
        \to     V^G \,,
        \quad   e
        \mapsto e(1) \,.
      \]
  \end{enumerate}
\end{example}


\begin{remark}
  If $V$, $W$ are two representations of $G$ over the same field, then by the restricting the equality from Lemma~\ref{lemma: equivariants are invariants} to the subset of $k$-linear maps on both sides, it follows that
  \[
      \Hom_G(V,W)
    = \Hom(V,W)^G \,.
  \]
  It follows in particular that $\Hom_G(V,W)$ is a $k$-vector space via pointwise addition und scalar multiplication.
\end{remark}


\begin{lemma}
\label{lemma: composition of morphisms of representations}
  Let $G$ be a group and let $U$, $V$, $W$, be representations of $G$.
  \begin{enumerate}
    \item
      The identity $\id_V \colon V \to V$ is a morphism of representations.
    \item
      If $f \colon U \to V$, $g \colon V \to W$ are morphism of representations, then $g \circ f \colon U \to W$ is also a morphism of representations.
  \end{enumerate}
\end{lemma}


\begin{fluff}
  Lemma~\ref{lemma: composition of morphisms of representations} shows that for any group $G$ and field $k$ the class of representations of $G$ over $k$ together with the morphisms of representations between them form a category, which we will denote by $\cRep{k}{G}$.
  As before there exists a functor from $\cRep{k}{G}$ to $\cRep{k}{G}$ which maps every representations $V$ to its invariants $V^G$ and every morphism of representations $f \colon V \to W$ to the restriction $f^G \colon V^G \to W^G$.
\end{fluff}


\begin{lemma}\label{lemma: ker and im subrepresentations}
  Let $V$, $W$ be representations of a group $G$, and let $f \colon V \to W$ be a morphism of representations.
  Then $\ker f$ is a subrepresentation of $V$ and $\im f$ is a subrepresentation of $W$.
\end{lemma}
\begin{proof}
  It is known from linear algebra that $\ker f$ is a vector subspace of $V$, and that $\im f$ is a vector subspace of $W$.
  
  Let $x \in \ker f$.
  Then $f(g.x) = g.f(x) = g.0 = 0$ for every $g \in G$, because $G$ acts linearly on $V$.
  This shows that $g.x \in \ker f$ for all $g \in G$, $x \in \ker f$, so that $\ker f$ is a subrepresentation.
  
  Let $y \in \im f$ with $y = f(x)$ for some $x \in V$.
  Then $g.y = g.f(x) = f(g.x) \in \im f$ for every $g \in G$.
  This shows that $\im f$ is a subrepresentation.
\end{proof}


\begin{lemma}
  \label{lemma: inj und surj for morphisms between irreducible}
  Let $V$, $W$ be representations of a group $G$ over the same field $k$.
  \begin{enumerate}
    \item
      If $V$ is irreducible then every nonzero morphism $V \to W$ is injective.
    \item
      If $W$ is irreducible then every nonzero morphism $V \to W$ is surjective.
  \end{enumerate}
\end{lemma}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item
      The kernel $\ker f$ is a proper subrepresentation of $V$, so that $\ker f = 0$.
    \item
      The image $\im f$ is a non-zero subreprentation of $W$, so that $\im f = W$.
  \qedhere
  \end{enumerate}
\end{proof}


\begin{corollary}[Schurâ€™s Lemma]
  Let $V$, $W$ be irreducible representations of a group $G$ over the same field $k$.
  \begin{enumerate}
    \item
      \label{enumerate: nonzero morphism is already an iso}
      Every nonzero morphism $f \colon V \to W$ is an isomorphism.
    \item
      If $V \ncong W$ then $\Hom_G(V,W) = 0$, and if $V \cong W$ then $\Hom_G(V,W) \neq 0$.
    \item
      The endomorphism ring $\End_G(V) = \Hom_G(V,V)$ is a divison ring, or skew field.
    \item
      \label{enumerate: morphism space is one-dimensional}
      If $k$ is algebraically closed (e.g.\ $k = \Complex$) and both $V$ and $W$ are finite dimensional then
      \[
              \Hom_G(V,W)
        \cong \begin{cases}
                k & \text{if $V \cong W$}     \,, \\
                0 & \text{if $V \ncong W$} \,.
              \end{cases}
      \]
  \end{enumerate}
\end{corollary}


\begin{proof}
  \leavevmode
  \begin{enumerate}
    \item 
      This follows directly from Lemma~\ref{lemma: inj und surj for morphisms between irreducible}.
    \item
      By \ref{enumerate: nonzero morphism is already an iso} there exists a non-zero isomorphism $V \to W$ if and only if $V \cong W$.
    \item
      This follows directly from~\ref{enumerate: nonzero morphism is already an iso}.
    \item
      For $V \ncong W$ this follows from \ref{enumerate: nonzero morphism is already an iso}, so it sufficies to consider the case $V \cong W$.
      Every isomorphism $\alpha \colon W \to V$ induces an isomorphism of vector spaces
      \[
                \alpha_*
        \colon  \Hom_G(V,W)
        \to     \Hom_G(V,V) \,,
        \quad   f
        \mapsto \alpha \circ f \,.
      \]
      We may therefore assume w.l.o.g.\ that $W = V$.
      
      Then every morphism of representations $f \colon V \to V$ has an eigenvalues $\lambda \in k$, for which $f - \lambda \id_V \colon V \to V$ is a morphism of representations with $\ker(f - \lambda \id_V) \neq 0$.
      Because $V$ is irreducible it follows that $f - \lambda \id_V = 0$, so that $f = \lambda \id_V$.
  \qedhere
  \end{enumerate}
\end{proof}


\begin{corollary}
  \label{corollary: irreducible representation of abelian groups}
  Let $k$ be an algebraically closed field, $G$ an abelian group and $V$ a finite-dimensional irreducible representation of $G$ over $k$.
  Then $\dim_k V = 1$.
\end{corollary}
\begin{proof}
  Because every two group elements $g, h \in G$ commute, it follows that the actions of $g$ and $h$ on $V$ commute, so that the map $\pi_g \colon V \to V$, $v \mapsto g.v$ is $G$-equivariant for every group element $g \in G$.
  Hence $\pi_g \in \End_G(V)$ for every $g \in G$.
  
  By Schurâ€™s Lemma we find that $\End_G(V) \cong k$, and so every group element $g \in G$ acts by multiplication with some scalar $\lambda \in k$.
  It follows that every $k$-linear subspace of $V$ is a subrepresentation of $V$.
  Since $V$ is irreducible we find that $V$ is one-dimensional.
\end{proof}


\begin{remark}
  Let $G$ be a group, $k$ an algebraically closed field and $V_1, \dotsc, V_n$ pairwise non-isomorphic irreducible representations of $G$ over $k$.
  Then
  \[
      \dim \Hom_G(V_i, V_j)
    = \delta_{ij}
  \]
  for all $i,j = 1, \dotsc, n$ by Schurâ€™s Lemma.
  Hence the representations $V_1, \dotsc, V_n$ can be thought of as â€œorthonormalâ€ with respect to $\dim \Hom_G(-,-)$.
  We will come back to this idea when we encouter characters of representations.
  % TODO: Add a link.
\end{remark}


\begin{remark}
  %TODO: Craft a better explanation.
  Assume $k$ is an algebraically closed field and $V$ a finite dimensional irreducible representation of some group $G$.
  Then $\End_G(V \oplus \dotsb \oplus V)$ and $\Mat(n \times n, k)$ are isomorpic as $k$-algebras by part~\ref{enumerate: morphism space is one-dimensional} of Schurâ€™s Lemma.
  
  More generally:
  If $V_1, \dotsc, V_r$ are pairwise non-isomorphic irreducible finite dimensional $k$-representations of some group $G$ and $W_i \coloneqq V_i^{\oplus n_i}$, then
  \begin{align*}
            \End_G(W_1 \oplus \dotsb \oplus W_r)
    &=      \End(V_1^{n_1} \oplus \dotsb \oplus V_n^{n_r})
    \\
    &\cong  \End(V_1^{n_1}) \oplus \dotsb \oplus \End(V_r^{n_r})
    \\
    &\cong  \Mat(n_1 \times n_1, k) \oplus \dotsb \oplus \Mat(n_r \times n_r, k)
  \end{align*}
  as $k$-algebras.
\end{remark}


\begin{remark}
  Part~\ref{enumerate: morphism space is one-dimensional} of Schurâ€™s Lemma holds true as long as the cardinality of the algebraically closed field $k$ is strictly larger than the $k$-dimension of $V$, i.e.\ as long as $\card k > \dim_k V$.
  As every algebraically closed field is infinite this generalizes \ref{enumerate: morphism space is one-dimensional} as stated above.
  
  To prove this generalization we may assume (as before) that $V = W$.
  We then need to show that every morphism of representations $f \colon V \to V$ is a scalar multiple of the identity $\id_V$.
  We proceed in two steps:
  We first show that there exists some nonzero polynomal $p(t) \in k[t]$ with $p(f) = 0$.
  We then show that $f = \lambda \id_V$ where $\lambda \in k$ is a root of $p(t)$.
  \begin{enumerate}[label=\arabic*)]
    \item
      Suppose that $p(f) \neq 0$ for every nonzero polynomial $p(t) \in k[t]$.
      Then $p(f) \colon V \to V$ is an isomorphism for every nonzero $p(t) \in k[t]$ because $\End_G(V)$ is a skew field.
      It follows that the $k$-vector space structure of $V$ can be extended to a $k(t)$-vector space structure given by
      \[
                  \frac{p(t)}{q(t)} \cdot v
        \defined  \left( p(f) q(f)^{-1} \right)(v)
      \]
      for all $p(t)/q(t) \in k(t)$, $v \in V$.
      
      Note that this is just the universal property of the localization:
      The ring homomorphism $\varphi \colon k[t] \to \End_G(V)$, $p(t) \mapsto p(f)$ maps every element of $S \defined k[t] \smallsetminus \{0\}$ to a unit, and therefore induces a ring homomorphism
      \[
                \Phi
        \colon  k(t)
        =       S^{-1} k[t]
        \to     \End_G(V) \,,
        \quad   p(t)/q(t)
        \mapsto p(f) q(f)^{-1} \,.
      \]
      By regarding $k(t)$ as a $k$-algebra and the map $\Phi$ as a homomorphism of $k$-algebras $k(t) \to \End_k(V)$, we find that $\Phi$ corresponds to a $k(t)$-module structure on $V$.
      This is precisely the $k(t)$-vector space structure from above.
      
      Because $V$ is a non-zero $k(t)$-vector space it follows that
      \[
              \dim_k V
        =     \dim_k k(t) \cdot \dim_{k(t)} V
        \geq  \card k \cdot 1
        =     \card k \,,
      \]
      which contradicts $\card k > \dim_k V$.
      For the (in)equalities we used the following facts from linear algebra:
      \begin{itemize}
        \item
          For the first equality we use that if $(b_i)_{i \in I}$ is a $k(t)$-basis of $V$, and $(c_j)_{j \in J}$ is a $k$-basis of $k(t)$, then $(c_j b_i)_{i \in I, j \in J}$ is a $k$-basis of $V$.
        \item
          For the inequality we use that the elements $1/(t-\lambda)$ with $\lambda \in k$ are $k$-linearly independent in $k(t)$, so that $\dim_k k(t) \geq \card k$.
        \item
          That $\dim_{k(t)} V \geq 1$ follows from $V$ being nonzero.
      \end{itemize}
      This contradiction shows that $p(f) \neq 0$ for some non-zero $p(t) \in k[t]$.
      We may assume w.l.o.g.\ that $p(t)$ is monic.
      
    \item
      Because $k$ is algebraically closed it follows that $p(t) = (t - \lambda_1) \dotsm (t - \lambda_n)$ for some $\lambda_i \in k$.
      In the skew field $\End_G(V)$ we then have the equality
      \[
          0
        = p(f)
        = (f - \lambda_1 \id_V) \dotsm (f - \lambda_n \id_V) \,,
      \]
      so that $f - \lambda_i = 0$ for some $i$, i.e.\ $f = \lambda_i \id_V$.
  \end{enumerate}
\end{remark}





\section{Maschkeâ€™s Theorem}


\begin{definition}
  Let $G$ be a group.
  A representation $V$ of $G$ (over a field $k$) is \emph{completely reducible} if
  \[
      V
    = V_1 \oplus \dotsb \oplus V_r
  \]
  for some irreducible subrepresentations $V_1, \dotsc, V_r \subseteq V$.
\end{definition}


\begin{remark}
  Not every representation is completely reducible, even if $k$ is algebraically closed.
  Consider for example the group
  \[
    G
    \defined \left\{
                \begin{pmatrix}
                  a & b \\
                  0 & c
                \end{pmatrix}
              \suchthat*
                \text{$a, b, c \in \Complex$ and $a,c \neq 0$}
              \right\}
    \subseteq \GL_2(\Complex)
  \]
  and the natural linear action of $G$ on $\Complex^2$.
  We have seen in example~\ref{example: upper triangular action on C2} that the corresponding representation is not irreducible, but still indecomposable.
  It can therefore not be decomposed into a direct sum of irreducible subrepresentations.
\end{remark}



\begin{example}
  \label{example: subrepresentations of natural action of Sn}
  Let $n \geq 2$ and let the symmetric group $S_n$ acts on $k^n$ so that
  \[
    \sigma.e_i = e_{\sigma(i)}
  \]
  for all $\sigma \in S_n$, $i = 1, \dotsc, n$, where $e_1, \dotsc, e_n$ denotes the standard basis of $k^n$.
  We denote this representation by $V$.
  We will show that $V$ is reducible, but completely reducible if and only if $\kchar k \nmid n$.

  For this we consider the linear subspaces $U_1, U_2 \subseteq k^n$ given by
  \begin{align*}
              U_1
    &\defined \{
                (x_1, \dotsc, x_n) \in V
              \suchthat
                x_1 = \dotsb = x_n
              \} \,,
    \\
              U_2
    &\defined \left\{
                (\lambda_1, \dotsc, \lambda_n) \in V
              \suchthat*
                \sum_{i=1}^n x_i = 0
              \right\} \,.
  \end{align*}
  These are proper non-zero subrepresentations of $V$ of complementary dimensions $\dim U_1 = 1$ and $\dim U_2 = n - 1$:
  Both subspaces are invariant under the action of $S_n$ because the conditions $x_1 = \dotsb = x_n$ and $\sum_{i=1}^n x_i = 0$ do not depend on the order of the $x_i$.
  A basis of $U_1$ is given by the single vector $(1, \dotsc, 1)$, while a basis of $U_2$ is given by the vectors of the form $(0, \dotsc, 0, 1, -1, 0, \dotsc, 0)$, of which there are $n-1$ many.
  Note that the exstence $U_1$ and $U_2$ already shows that $V$ itself is reducible.
  
  To determine when $V$ is completely reducible we note that the subrepresentations $U_1, U_2$ are the only non-zero proper subrepresentations of $V$.
  To see this we consider an arbitrary non-zero proper subrepresentation $U \subseteq V$ and distinguish between two cases:
  \begin{itemize}
    \item
      If for every $(x_1, \dotsc, x_n) \in U$ we have that $x_1 = \dotsb  = x_n$, then $U$ is contained in $U_1$.
      Because $U$ is non-zero it follows from $\dim U_1 = 1$ that $U = U_1$.
    \item
      Otherwise there exists some $v = (x_1, \dotsc, x_n) \in U$ with $x_i \neq x_j$ for some $i,j$.
      By using the action of $S_n$ on $U$ we may assume w.l.o.g.\ that $x_1 \neq x_2$.
      Then $v = (x_1, x_2, x_3, \dotsc, x_n)$ and $(1\,2).v = (x_2, x_1, x_3, \dotsc, x_n)$, so that
      \[
            v - (1\,2).v
        =   (x_1 - x_2, x_2 - x_1, 0, \dotsc, 0)
        \in U \,.
      \]
      After dividing by $x_1 - x_2 \neq 0$ we arrive at
      \[
            (1, -1, 0, \dotsc, 0)
        \in U \,.
      \]
      By using the action of $S_n$ on $U$ it further follows that all vectors of the form
      \[
        (0, \dotsc, 0, 1, -1, 0, \dotsc, 0)
      \]
      are contained in $U$.
      Because these vectors form a $k$-basis of the subrepresentation $U_2$ it follows that $U_2 \subseteq U$.
      Because $U$ is a proper subrepresentation it further follows from $\dim U_2 = n-1$ that $U = U_2$.
  \end{itemize}
  
  Because $V$ itself is not irreducible, it follows that $V$ is completely reducible if and only both $U_1$ and $U_2$ are irreducible and $V = U_1 \oplus U_2$, as no other decomposition into subrepresentations is possible.
  \begin{itemize}
    \item
      The condition $V = U_1 \oplus U_2$ is equivalent to $U_1 \cap U_2$ because $U_1$ and $U_2$ have complementary dimensions.
      Because $U_1$ is one-dimensional this holds if and only if $U_1 \nsubseteq U_2$.
    \item
      The representation $U_1$ is one-dimensional, and therefore irreducible.
      As every subrepresentation of $U_2$ is also a subrepresentation of $V$ it follows that $U_2$ is irreducible if and only if $U_1$ is not a proper subrepresentation of $U_2$.
  \end{itemize}
  Hence $V$ is completely reducible if and only if $U_1 \nsubseteq U_2$, which is equivalent to $\kchar k \nmid n$.
\end{example}


\begin{example}
  \label{example: complex representations of finite abelian groups are completely reducible}
  \begin{enumerate}
    \item
      Let $k = \Complex$ and let the cyclic group $G = \Integer/n$ act linearly on the vector space $V \coloneqq \Complex^n$ by rotating the coordinates to the left, i.e.
      \[
          \overline{k}.(x_1, x_2, \dotsc, x_n)
        = (x_2, \dotsc, x_n, x_1) \,.
      \]
      The representation $V$ is completely reducible, with the irreducible subrepresentations being one-dimensional by Corollary~\ref{corollary: irreducible representation of abelian groups}.
      
      Let $\omega_0, \dotsc, \omega_{n-1} \in \Complex$ denotes the $n$-th roots of unity, i.e.\ $\omega_j = e^{2 \pi i j/n}$.
      Then the group $G$ acts on the vectors $v_0, \dotsc, v_{n-1} \in V$ with
      \[
          v_j
        = (1, \omega_j, \omega_j^2, \dotsc, \omega_j^{n-1})
      \]
      by mutliplication with scalars, namely
      \[
          \overline{1}.v_j
        = \omega_j v_j
      \]
      for every $j = 0, \dotsc, n-1$.
      The one-dimensional subspaces $U_j \coloneqq \gen{ v_j }_\Complex$ are therefore subrepresentations of $V$.
      The vectors $v_0, \dotsc, v_{n-1}$ are linearly independent because the Vandermonte determinant
      \[
          \det
          \begin{pmatrix}
            1       & \omega_0      & \omega_0^2    & \cdots  & \omega_0^{n-1}      \\
            1       & \omega_1      & \omega_1^2    & \cdots  & \omega_1^{n-1}      \\
            1       & \omega_2      & \omega_2^3    & \cdots  & \omega_2^{n-1}      \\
            \vdots  & \vdots        & \vdots        & \ddots  & \vdots              \\
            1       & \omega_{n-1}  & \omega_{n-1}  & \cdots  & \omega_{n-1}^{n-1}
          \end{pmatrix}
        = \prod_{i > j} (\omega_i - \omega_j)
      \]
      is non-zero.
      The resulting decomposition $V = U_0 \oplus \dotsb U_{n-1}$ is a decomposition into one-dimensional subrepresentations.
    \item
      More generally, let $G$ be a finite abelian groups and $k$ an algebraically closed field with $\kchar k = 0$.
      Then every representation $V$ of $G$ over $k$ is completely reducible, with the irreducible subrepresentations being one-dimensional by Corollary~\ref{corollary: irreducible representation of abelian groups}:
    
      Let $G = \{1 = g_1, g_2, \dotsc, g_n\}$ and let $\rho \colon G \to \GL(V)$ be the group homomorphism which corresponds to the linear action of $G$ on $V$.
      Then $\rho(g)^n = \rho(g^n) = \rho(1) = \id_V$ for every $g \in G$, so that every endomorphism $\rho(g) \colon V \to V$ satisfies the polynomial identity $\rho(g)^n - \id_V = 0$, i.e.\ satisfies the polynomial $p(t) \defined t^n - 1 \in k[t]$.
      The polynomials $p(t)$ decomposes into linear factors because $k$ is algebraically closed.
      The roots of $p(t)$ are the $n$-th roots of unity $w_1, \dotsc, w_n$, which are pairwise different because $\kchar k = 0$.
      Hence $\rho(g)$ satisfies the polynomial $p(t)$ which decomposes into pairwise different linear factors $p(t) = (t - w_1) \dotsm (t - w_n)$.
      It follows from linear algebra that every $\rho(g)$ is diagonalizable with possible eigenvalues $w_1, \dotsc, w_n$.
      
      Because $G$ is abelian it further follows that the endomorphisms $\rho(g)$ are simultaneously diagonalizable, i.e.\ there exists a decomposition
      \[
          V
        = U_1 \oplus \dotsb \oplus U_r
      \]
      such that every $\rho(g)$ acts on each $U_i$ by multiplication with some scalar $\lambda_i(g) \in k$, namely some of the roots of unity $w_1, \dotsc, w_n$.
      It then follows that every linear subspace of every $U_i$ is a subrepresentation.
      By decomposing every $U_i$ into a direct sum of one-dimensional linear subspaces we arrive at a decomposition of $V$ into one-dimensional subrepresentations.
  \end{enumerate}
\end{example}



\begin{theorem}[Maschkeâ€™s theorem]
  Let $G$ be a finite group and let $k$ be a field such that $\kchar k \nmid |G|$.
  Then any finite dimensional representation of $G$ over $k$ is completely reducible.
\end{theorem}
\begin{proof}
  It is enough to show that every subrepresentation $U \subseteq V$ has a direct complement $W \subseteq V$ which is again a subrepresentation, i.e.\ such that $V = U \oplus W$ as (sub)representations.
  
  Given a subrepresentation $U \subseteq V$ let $W \subseteq V$ be a direct complement as vector spaces.
  Then $V = U \oplus W$ as vector spaces.
  Let $p \colon V \to V$ be the projection onto $U$ along $W$, i.e.\ the unique $k$-linear map $V \to V$ with
  \[
      p(u + w)
    = u
  \]
  for all $u \in U$, $w \in W$.
  Note that $\im p = U$.
  The map $p$ is not necessarily $G$-equivariant, which is why we want to replace $p$ with a $G$-equivariant projection $\hat{p} \colon V \to V$ onto $U$.
  We define $\hat{p}$ as
  \[
              \hat{p}(v)
    \defined  \frac{1}{|G|} \sum_{g \in G} g^{-1}.p(g.v) \,.
  \]
  The sum is well defined because $|G|$ is finite, and $|G| \in k$ is nonzero because $\kchar k \nmid |G|$.
  
  For all $g \in G$, $v \in V$ we have that $p(g.v) \in \im p = U$, and because $U$ is a subrepresentation therefore also $g^{-1}.p(g.v) \in U$.
  It follows that $\im \hat{p} \subseteq U$.
  From $p$ being a projection onto $U$ it follows that
  \[
      \hat{p}(u)
    = \frac{1}{|G|} \sum_{g \in G} g^{-1}.p(g.u)
    = \frac{1}{|G|} \sum_{g \in G} g^{-1}.g.u
    = \frac{1}{|G|} \sum_{g \in G} u
    = \frac{1}{|G|} |G| \cdot u
    = u
  \]
  for every $u \in U$.
  Together with $\im \hat{p} \subseteq U$ this shows that $\hat{p}$ is again a projection onto $U$ (but not along necessarily $W$).
  The projection $\hat{p}$ is $G$-equivariant because 
  \begin{align*}
        \hat{p}(h.v)
    &=  \frac{1}{|G|} \sum_{g \in G} g^{-1}.p(gh.v)
     =  \frac{1}{|G|} \sum_{g \in G} h.h^{-1}.g^{-1}.p(g.h.v) \\
    &=  \frac{1}{|G|} \sum_{\bar{g} \in G} h.\bar{g}^{-1}.p(\bar{g}.v)
     =  h.\hat{p}(v)
  \end{align*}
  for all $h \in G$, $v \in V$.
  
  Because $\hat{p}$ is a projection onto $U$ it follows that $V = \im \hat{p} \oplus \ker \hat{p} = U \oplus \ker \hat{p}$.
  The direct complement $\ker \hat{p}$ is a subrepresentation because $\hat{p}$ is $G$-equivariant.
\end{proof}


\begin{example}
  \leavevmode
  \begin{enumerate}
    \item
      Consider the linear action of the symmetric group $S_n$ on the polynomial ring $k[X_1, \dotsc, X_n]$ given by
      \[
          \sigma.p(X_1, \dotsc, X_n)
        = p(X_{\sigma(1)}, \dotsc, X_{\sigma(n)})
      \]
      for all $\sigma \in S_n$, $p(X_1, \dotsc, X_n) \in k[X_1, \dotsc, X_n]$.
      For every $d \geq 0$ let $k[X_1, \dotsc, X_n]_d$ denote the span of all monomials $X_1^{d_1} \dotsm X_n^{d_n}$ of degree $d_1 + \dotsb + d_n = d$ and consider the resulting decomposition $k[X_1, \dotsc, X_n] = \bigoplus_{d \geq 0} k[X_1, \dotsc, X_n]_d$ into finite-dimensional subrepresenations.
      If $\kchar k = 0$ then it follows from Maschkeâ€™s theorem that every $k[X_1, \dotsc, X_n]_d$ is completely reducible.
      Hence $k[X_1, \dotsc, X_n]$ is completely reducible.
    \item
      By combining Maschkeâ€™s theorem with Corollary~\ref{corollary: irreducible representation of abelian groups} we can reconstruct the result from Example~\ref{example: complex representations of finite abelian groups are completely reducible}:
      Under the given conditions the representation $V$ decomposes into a direct sum of irreducible subrepresentations, each of which is one-dimensional.
      The actions on these one-dimensional subrepresentations must be given by multiplication with scalars from $k^\times$.
      Because $G$ is finite, so that every element $g \in G$ has finite order, it then follows that these scalars must have finite order in $k^\times$, i.e.\ must be roots of unity.
      
    \item
      Maschkeâ€™s theorem confirmes our result from Example~\ref{example: subrepresentations of natural action of Sn}:
      Note that for $|S_n| = n!$ and that for every field $k$ we have that $\kchar k \nmid n!$ if and only if $\kchar k \nmid n$.
      This holds because $\kchar k$ is either $0$ or prime.
      Note however that in Example~\ref{example: subrepresentations of natural action of Sn} the converse of Maschkeâ€™s theorem does also hold:
      If $\kchar K \mid |S_n|$, then the given representations is not completely reducible.
      This is not a complete coincide:
  \end{enumerate}
\end{example}


\begin{warning}
  If $\kchar k \mid |G|$ then Maschkeâ€™s theorem does not hold:
  The left regular representation $k[G]$ is then not completely reducible.
  We will later give a proof of this, when we have another characterization of complete reducibility available.
\end{warning}


\begin{fluff}
  \label{fluff: orthogonality proof of Maschke}
  It is worthwhile to mention another proof of Maschkeâ€™s theorem for the case that $k \in \{\Rational, \Real, \Complex\}$:
  
  Suppose first that $V$ is endowed with an inner product $\bil{\cdot}{\cdot}$ which is $G$-invariant in the sense that
  \[
      \bil{g.v_1}{g.v_2}
    = \bil{v_1}{v_2}
  \]
  for all $g \in G$, $v_1, v_2 \in V$.
  Then for every subrepresentation $U \subseteq V$ the orthogonal complement $U^\perp \subseteq V$ is again a subrepresentation:
  It is a linear subspace, and for all $g \in G$, $v \in U^\perp$ one has that
  \[
      \bil{g.v}{u}
    = \bil{g.v}{g.g^{-1}.u}
    = \bil{v}{g^{-1}.u}
    = 0
  \]
  for every $u \in U$ because $g^{-1}.u \in U$.
  It follows that for every subrepresentation $U \subseteq V$ there exists a subrepresentation $W \subseteq V$ with $V = U \oplus W$, namely $W = U^\perp$.
  
  It remains to show that there exists a $G$-invariant inner product on $V$.
  For this we start off with an arbitrary inner product $\bil{\cdot}{\cdot}$ on $V$ and then define $\bil{\cdot}{\cdot}'$ by
  \[
              \bil{v_1}{v_2}'
    \defined  \frac{1}{|G|} \sum_{g \in G} \bil{g.v_1}{g.v_2}
  \]
  for all $v_1, v_2 \in V$.
  Then $\bil{\cdot}{\cdot}'$ is also an inner product on $V$:
  The bilinearity (resp.\ sesquilinearity) of $\bil{\cdot}{\cdot}'$ follows from the one of $\bil{\cdot}{\cdot}$ and the linearity of the $G$-action.
  For every $v \in V$ with $v \neq 0$ we have that
  \[
              \bil{v}{v}'
    \defined  \frac{1}{|G|} \bil{g.v}{g.v}
    \geq      \frac{\bil{v}{v}}{|G|}
    >         0 \,,
  \]
  so that $\bil{\cdot}{\cdot}'$ is positive definite.
  This new inner product $\bil{\cdot}{\cdot}'$ is $G$-invariant because
  \[
      \bil{g.v_1}{g.v_2}'
    = \frac{1}{|G|} \sum_{h \in G} \bil{h.g.v_1}{h.g.v_2}
    = \frac{1}{|G|} \sum_{h' \in G} \bil{h'.v_1}{h'.v_2}
    = \bil{v_1}{v_2}
  \]
  for all $v_1, v_2 \in V$.
\end{fluff}


\begin{remark}
  Both proofs of Maschkeâ€™s theorem show the seemingly stronger statement that every subrepresentation $U \subseteq V$ has a direct complement which is again a subrepresenation.
  We will see in Proposition~\ref{proposition: characterisation semisimple modules} that both of these conditions are actually equivalent, i.e.\ that a representation $V$ is completely reducible if and only if every subrepresentation $U \subseteq V$ has a direct complement which is again a subrepresentation.
\end{remark}


\begin{remark}
  Both proofs of Maschkeâ€™s theorem make use of a powerful technique, the so called \emph{projection onto the invariants}:
  If $V$ is a representation of a group $G$ over a field $k$ with $\kchar k \nmid |G|$, then consider the map
  \[
              \widehat{(-)} \;
    \colon    V
    \to       V^G \,,
    \quad     v
    \mapsto   \hat{v}
    \defined  \frac{1}{|G|} \sum_{g \in G} g.v \,.
  \]
  This map â€œaveragesâ€ a vector $v \in V$ over the linear group action.
  The map $\widehat{(-)}$ is linear because $G$ acts linearly on $V$.
  For every $v \in V$ the element $\hat{v}$ is $G$-invariant because
  \[
      g.\hat{v}
    = g.\left( \frac{1}{|G|} \sum_{h \in G} h.v \right)
    = \frac{1}{|G|} \sum_{h \in G} (gh).v
    = \frac{1}{|G|} \sum_{g' \in G} g'.v
    = \hat{v} \,.
  \]
  If $v$ is already invariant itself then $g.v = v$ for every $g \in G$, so that
  \[
      \hat{v}
    = \frac{1}{|G|} \sum_{g \in G} g.v
    = \frac{1}{|G|} \sum_{g \in G} v
    = \frac{|G|}{|G|} v
    = v \,.
  \]
  Together this shows that $\widehat{(-)}$ is a projection onto the subspace of invariants $V^G \subseteq V$.
  
  In the first proof of Maschkeâ€™s theorem it follows for the linear map $p \in \Hom(V,V)$ that $\hat{p} \in \Hom(V,V)^G = \Hom_G(V,V)$, so that $\hat{p}$ is a morphism of representations.
  (Note however, that from this argumentations is it not yet clear, that $\hat{p}$ is again a projection onto the subrepresentation $U$.)
  %TODO: Why is \hat{p} again a projection?
  
  In the second proof we let $G$ act linearly on the space $\operatorname{BF}(V)$ (resp.\ $\operatorname{SF}(V)$) of bilinear (resp.\ sesquilinear) forms $\beta \colon V \times V \to k$ via
  \[
      (g.\beta)(v_1, v_2)
    = \beta\left( g^{-1}.v_1, g^{-1}.v_2 \right)
  \]
  for all $g \in G$, $v_1, v_2 \in V$.
  Then the bilinear (resp.\ sesquilinear) form $\beta$ is invariant in the sense of \ref{fluff: orthogonality proof of Maschke} if and only if it is invariant in the sense of groups actions.
  It is then only natural to construct the required invariant inner product $\bil{\cdot}{\cdot}'$ by projection the given inner product $\bil{\cdot}{\cdot}$ onto the invariants $\operatorname{BF}(V)^G$ (resp.\ $\operatorname{SF}(V)^G$).
\end{remark}





% \begin{example}
%   In general it is hard to compute a decomposition using Maschkeâ€™s theorem in practice!
%   
%   Let $G = S_3$.
%   Let $V = k[G]$ be viewed as a representation of $G$ via the left multiplication, i.e.\
%   \[
%       h.\left( \sum_{g \in G} a_g g \right)
%     = \sum_{g \in G} a_g hg \,.
%   \]
%   Let $k = \Complex$, hence Maschkeâ€™s theorem holds. We want to find a decomposition of $k[G]$. Recall that $S_3 = \gen{s,t}$ where $s = (1 \; 2)$ and $t = (2 \; 3)$. We claim that
%   \[
%       k[G]
%     = V_{\text{triv}} \oplus V_{\text{sgn}} \oplus V_1 \oplus V_2
%   \]
%   where
%   \begin{align*}
%                 V_{\text{triv}}
%     &\coloneqq  \vspan\left(\sum_{g \in G} g \right) = \vspan(e+s+t+st+ts+sts) \,,
%     \\
%                 V_{\text{sgn}}
%     &\coloneqq  \vspan\left(e-s-t+st+ts-sts\right) \,,
%     \\
%                 V_1
%     &\coloneqq  \vspan\left(e+s-ts, t+ts-st-sts\right) \,,
%     \\
%                 V_2
%     &\coloneqq  \vspan\left(s+st-sts,e+t-s-st\right) \,.
%   \end{align*}
%   Note that $G$ acts trivially on $V_{\text{triv}}$ and by multiplication with $-1$ on $V_{\text{sgn}}$ , hence $V_{\text{triv}}$ and $V_{\text{sgn}}$ are subrepresentations.
%   One can also check that $V_1$ and $V_2$ are irreducible subrepresentations which are isomorphic.
% \end{example}



